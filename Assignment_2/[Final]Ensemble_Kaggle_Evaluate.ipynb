{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce GTX 1070\n",
      "Memory Usage:\n",
      "Allocated: 0.0 MB\n",
      "Cached:    0.0 MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**2,1), 'MB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**2,1), 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(folder):\n",
    "    train_zip = folder + '/train_images.zip'\n",
    "    test_zip = folder + '/test_images.zip'\n",
    "    if not os.path.exists(train_zip) or not os.path.exists(test_zip):\n",
    "        raise(RuntimeError(\"Could not find \" + train_zip + \" and \" + test_zip\n",
    "              + ', please download them from https://www.kaggle.com/c/nyu-cv-fall-2018/data '))\n",
    "    # extract train_data.zip to train_data\n",
    "    train_folder = folder + '/train_images'\n",
    "    if not os.path.isdir(train_folder):\n",
    "        print(train_folder + ' not found, extracting ' + train_zip)\n",
    "        zip_ref = zipfile.ZipFile(train_zip, 'r')\n",
    "        zip_ref.extractall(folder)\n",
    "        zip_ref.close()\n",
    "    # extract test_data.zip to test_data\n",
    "    test_folder = folder + '/test_images'\n",
    "    if not os.path.isdir(test_folder):\n",
    "        print(test_folder + ' not found, extracting ' + test_zip)\n",
    "        zip_ref = zipfile.ZipFile(test_zip, 'r')\n",
    "        zip_ref.extractall(folder)\n",
    "        zip_ref.close()\n",
    "\n",
    "    # make validation_data by using images 00000*, 00001* and 00002* in each class\n",
    "    val_folder = folder + '/val_images'\n",
    "    if not os.path.isdir(val_folder):\n",
    "        print(val_folder + ' not found, making a validation set')\n",
    "        os.mkdir(val_folder)\n",
    "        for dirs in os.listdir(train_folder):\n",
    "            if dirs.startswith('000'):\n",
    "                os.mkdir(val_folder + '/' + dirs)\n",
    "                for f in os.listdir(train_folder + '/' + dirs):\n",
    "                    if f.startswith('00000') or f.startswith('00001') or f.startswith('00002'):\n",
    "                        # move file to validation folder\n",
    "                        os.rename(train_folder + '/' + dirs + '/' + f, val_folder + '/' + dirs + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'C:/Users/tiany/Assignment_2'\n",
    "initialize_data(address)\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'batch_size': 64,\n",
    "    'epochs':100,\n",
    "    'lr':0.00005,\n",
    "    'momentum':0.5,\n",
    "    'seed':1,\n",
    "    'log_interval':100,\n",
    "    'weight_decay':1e-2\n",
    "})\n",
    "\n",
    "kwargs = {'num_workers': 12, 'pin_memory': True}\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(address + '/train_images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(address + '/val_images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=args.batch_size, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = 43\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=4)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(1000, 200)\n",
    "        self.fc2 = nn.Linear(200, nclasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
    "        x = x.view(-1, 250*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    \"\"\" Reference:\n",
    "    GoogLeNet: \n",
    "    Going Deeper with Convolutions\n",
    "    https://arxiv.org/abs/1409.4842v1\n",
    "    Github Reference: https://github.com/xuchaoxi/pytorch-classification/blob/master/models/googlenet.py\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, _1x1_, _3x3reduce_, _3x3_, _5x5reduce_, _5x5_, pool_proj):\n",
    "        super(Inception, self).__init__()\n",
    "        self.con1x1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, _1x1_, kernel_size=1),\n",
    "            nn.BatchNorm2d(_1x1_),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.con1x1_3x3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, _3x3reduce_, kernel_size=1),\n",
    "            nn.BatchNorm2d(_3x3reduce_),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(_3x3reduce_, _3x3_, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(_3x3_),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Conv2d(_3x3_, _3x3_, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(_3x3_),\n",
    "            #nn.ReLU(True),\n",
    "        )\n",
    "        self.con1x1_5x5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, _5x5reduce_, kernel_size=1),\n",
    "            nn.BatchNorm2d(_5x5reduce_),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(_5x5reduce_, _5x5_, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(_5x5_),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(_5x5_, _5x5_, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(_5x5_),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.mp3x3_con1x1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.Conv2d(in_channels, pool_proj, kernel_size = 1),\n",
    "            nn.BatchNorm2d(pool_proj),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        output_con1x1 = self.con1x1(inputs)\n",
    "        output_con1x1_3x3 = self.con1x1_3x3(inputs)\n",
    "        output_con1x1_5x5 = self.con1x1_5x5(inputs)\n",
    "        output_mp3x3_con1x1 = self.mp3x3_con1x1(inputs)\n",
    "        output = torch.cat([output_con1x1,output_con1x1_3x3,output_con1x1_5x5,output_mp3x3_con1x1], dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self._3a = Inception(192,  64,  96, 128, 16, 32, 32)\n",
    "        self._3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "        self._4a = Inception(480, 192,  96, 208, 16,  48,  64)\n",
    "        self._4b = Inception(512, 160, 112, 224, 24,  64,  64)\n",
    "        self._4c = Inception(512, 128, 128, 256, 24,  64,  64)\n",
    "        self._4d = Inception(512, 112, 144, 288, 32,  64,  64)\n",
    "        self._4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "        self._5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self._5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "        self.dropout = nn.Dropout2d(0.4)\n",
    "        self.linear = nn.Linear(1024, 43)\n",
    "    def forward(self, input):\n",
    "        output_pl = self.pre_layers(input)\n",
    "        output_3a = self._3a(output_pl)\n",
    "        output_3b = self._3b(output_3a)\n",
    "        output_mp1 = self.maxpool(output_3b)\n",
    "        output_4a = self._4a(output_mp1)\n",
    "        output_4b = self._4b(output_4a)\n",
    "        output_4c = self._4c(output_4b)\n",
    "        output_4d = self._4d(output_4c)\n",
    "        output_4e = self._4e(output_4d)\n",
    "        output_mp2 = self.maxpool(output_4e)\n",
    "        output_5a = self._5a(output_mp2)\n",
    "        output_5b = self._5b(output_5a)\n",
    "        output_ap = self.avgpool(output_5b)\n",
    "        output_drop = self.dropout(output_ap)\n",
    "        output_ = output_drop.view(output_drop.size(0), -1)\n",
    "        output_ = self.linear(output_)\n",
    "        return output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_loc = 'C:/Users/tiany/Assignment_2/submissions/'\n",
    "model_GooNet2 = GoogLeNet().to(device)\n",
    "model_GooNet2.load_state_dict(torch.load(model_loc + \"model_GoogLeNet_2-85-3825.pth\"))\n",
    "model_GooNet31 = GoogLeNet().to(device)\n",
    "model_GooNet31.load_state_dict(torch.load(model_loc + \"model_GoogLeNet_3_81-3835.pth\"))\n",
    "model_GooNet32 = GoogLeNet().to(device)\n",
    "model_GooNet32.load_state_dict(torch.load(model_loc + \"model_GoogLeNet_3_89-3848.pth\"))\n",
    "model_GooNet33 = GoogLeNet().to(device)\n",
    "model_GooNet33.load_state_dict(torch.load(model_loc + \"model_GoogLeNet_3_99-3848.pth\"))\n",
    "model_Basic = Net().to(device)\n",
    "model_Basic.load_state_dict(torch.load(model_loc + \"model_Net_5_89-3756.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kaggle_single_model(filename, model):\n",
    "    \"\"\"\n",
    "    This function gives a result of a single model\n",
    "    For example: generate_kaggle_single_model(\"test.csv\", model_GooNet2)\n",
    "    filename: String || the name of the output files\n",
    "    model: pytorch model\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    test_dir = address + '/test_images'\n",
    "    def pil_loader(path):\n",
    "        # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "        with open(path, 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                return img.convert('RGB')\n",
    "    output_file = open(filename, \"w\")\n",
    "    output_file.write(\"Filename,ClassId\\n\")\n",
    "    for f in tqdm(os.listdir(test_dir)):\n",
    "        if 'ppm' in f:\n",
    "            data = data_transforms(pil_loader(test_dir + '/' + f))\n",
    "            data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "            data = Variable(data, volatile=True).to(device)\n",
    "            output = model(data)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "            file_id = f[0:5]\n",
    "            output_file.write(\"%s,%d\\n\" % (file_id, pred))\n",
    "    output_file.close()\n",
    "\n",
    "    print(\"Succesfully wrote \" + filename + ', you can upload this file to the kaggle '\n",
    "          'competition at https://www.kaggle.com/c/nyu-cv-fall-2019/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kaggle_ensemble_model(filename, models):\n",
    "    \"\"\"\n",
    "    This function gaves the ensemble model result\n",
    "    For example: \n",
    "    models_test = [model_GooNet2, model_GooNet31, model_GooNet32, model_GooNet33, model_Basic]\n",
    "    generate_kaggle_ensemble_model('test_ensemble.csv',models_test)\n",
    "    ====================================================================================\n",
    "    filename: String || the name of the output files\n",
    "    models: a list with pytorch models as items\n",
    "    \"\"\"\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "    test_dir = address + '/test_images'\n",
    "    def pil_loader(path):\n",
    "        # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "        with open(path, 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                return img.convert('RGB')\n",
    "    output_file = open(filename, \"w\")\n",
    "    output_file.write(\"Filename,ClassId\\n\")\n",
    "    for f in tqdm(os.listdir(test_dir)):\n",
    "        if 'ppm' in f:\n",
    "            data = data_transforms(pil_loader(test_dir + '/' + f))\n",
    "            data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "            data = Variable(data, volatile=True).to(device)\n",
    "            outputs = []\n",
    "            for model in models:\n",
    "                outputs.append(model(data))\n",
    "            output = torch.mean(torch.stack(outputs),dim = 0)\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "            file_id = f[0:5]\n",
    "            output_file.write(\"%s,%d\\n\" % (file_id, pred))\n",
    "    output_file.close()\n",
    "\n",
    "    print(\"Succesfully wrote \" + filename + ', you can upload this file to the kaggle '\n",
    "          'competition at https://www.kaggle.com/c/nyu-cv-fall-2019/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/12631 [00:00<?, ?it/s]c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  app.launch_new_instance()\n",
      "c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      " 80%|████████████████████████████████████████████████████████████▌               | 10074/12631 [15:06<03:42, 11.47it/s]"
     ]
    }
   ],
   "source": [
    "models_test = [model_GooNet2, model_GooNet31, model_GooNet32, model_GooNet33, model_Basic]\n",
    "generate_kaggle_ensemble_model('test_ensemble.csv',models_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
