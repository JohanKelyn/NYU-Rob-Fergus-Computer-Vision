{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import lr_scheduler\n",
    "import copy\n",
    "\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce GTX 1070\n",
      "Memory Usage:\n",
      "Allocated: 0.0 MB\n",
      "Cached:    0.0 MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**2,1), 'MB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**2,1), 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(folder):\n",
    "    train_zip = folder + '/train_images.zip'\n",
    "    test_zip = folder + '/test_images.zip'\n",
    "    if not os.path.exists(train_zip) or not os.path.exists(test_zip):\n",
    "        raise(RuntimeError(\"Could not find \" + train_zip + \" and \" + test_zip\n",
    "              + ', please download them from https://www.kaggle.com/c/nyu-cv-fall-2018/data '))\n",
    "    # extract train_data.zip to train_data\n",
    "    train_folder = folder + '/train_images'\n",
    "    if not os.path.isdir(train_folder):\n",
    "        print(train_folder + ' not found, extracting ' + train_zip)\n",
    "        zip_ref = zipfile.ZipFile(train_zip, 'r')\n",
    "        zip_ref.extractall(folder)\n",
    "        zip_ref.close()\n",
    "    # extract test_data.zip to test_data\n",
    "    test_folder = folder + '/test_images'\n",
    "    if not os.path.isdir(test_folder):\n",
    "        print(test_folder + ' not found, extracting ' + test_zip)\n",
    "        zip_ref = zipfile.ZipFile(test_zip, 'r')\n",
    "        zip_ref.extractall(folder)\n",
    "        zip_ref.close()\n",
    "\n",
    "    # make validation_data by using images 00000*, 00001* and 00002* in each class\n",
    "    val_folder = folder + '/val_images'\n",
    "    if not os.path.isdir(val_folder):\n",
    "        print(val_folder + ' not found, making a validation set')\n",
    "        os.mkdir(val_folder)\n",
    "        for dirs in os.listdir(train_folder):\n",
    "            if dirs.startswith('000'):\n",
    "                os.mkdir(val_folder + '/' + dirs)\n",
    "                for f in os.listdir(train_folder + '/' + dirs):\n",
    "                    if f.startswith('00000') or f.startswith('00001') or f.startswith('00002'):\n",
    "                        # move file to validation folder\n",
    "                        os.rename(train_folder + '/' + dirs + '/' + f, val_folder + '/' + dirs + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'D:/Sync/Courses/Level_3/CV/Courant-CSCI-2271-Computer-Vision/Assignment_2'\n",
    "initialize_data(address)\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'batch_size': 64,\n",
    "    'epochs':100,\n",
    "    'lr':0.00005,\n",
    "    'momentum':0.5,\n",
    "    'seed':1,\n",
    "    'log_interval':100,\n",
    "    'weight_decay':1e-2\n",
    "})\n",
    "\n",
    "kwargs = {'num_workers': 12, 'pin_memory': True}\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(address + '/train_images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(address + '/val_images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=args.batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception(nn.Module):\n",
    "    \"\"\" Reference:\n",
    "    GoogLeNet: \n",
    "    Going Deeper with Convolutions\n",
    "    https://arxiv.org/abs/1409.4842v1\n",
    "    Github Reference: https://github.com/xuchaoxi/pytorch-classification/blob/master/models/googlenet.py\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, _1x1_, _3x3reduce_, _3x3_, _5x5reduce_, _5x5_, pool_proj):\n",
    "        super(Inception, self).__init__()\n",
    "        self.con1x1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, _1x1_, kernel_size=1),\n",
    "            nn.BatchNorm2d(_1x1_),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.con1x1_3x3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, _3x3reduce_, kernel_size=1),\n",
    "            nn.BatchNorm2d(_3x3reduce_),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(_3x3reduce_, _3x3_, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(_3x3_),\n",
    "            nn.ReLU(True),\n",
    "            #nn.Conv2d(_3x3_, _3x3_, kernel_size=3, padding=1),\n",
    "            #nn.BatchNorm2d(_3x3_),\n",
    "            #nn.ReLU(True),\n",
    "        )\n",
    "        self.con1x1_5x5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, _5x5reduce_, kernel_size=1),\n",
    "            nn.BatchNorm2d(_5x5reduce_),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(_5x5reduce_, _5x5_, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(_5x5_),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(_5x5_, _5x5_, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(_5x5_),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.mp3x3_con1x1 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.Conv2d(in_channels, pool_proj, kernel_size = 1),\n",
    "            nn.BatchNorm2d(pool_proj),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        output_con1x1 = self.con1x1(inputs)\n",
    "        output_con1x1_3x3 = self.con1x1_3x3(inputs)\n",
    "        output_con1x1_5x5 = self.con1x1_5x5(inputs)\n",
    "        output_mp3x3_con1x1 = self.mp3x3_con1x1(inputs)\n",
    "        output = torch.cat([output_con1x1,output_con1x1_3x3,output_con1x1_5x5,output_mp3x3_con1x1], dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        self.pre_layers = nn.Sequential(\n",
    "            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self._3a = Inception(192,  64,  96, 128, 16, 32, 32)\n",
    "        self._3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "        self._4a = Inception(480, 192,  96, 208, 16,  48,  64)\n",
    "        self._4b = Inception(512, 160, 112, 224, 24,  64,  64)\n",
    "        self._4c = Inception(512, 128, 128, 256, 24,  64,  64)\n",
    "        self._4d = Inception(512, 112, 144, 288, 32,  64,  64)\n",
    "        self._4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "        self._5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
    "        self._5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
    "        self.dropout = nn.Dropout2d(0.4)\n",
    "        self.linear = nn.Linear(1024, 43)\n",
    "    def forward(self, input):\n",
    "        output_pl = self.pre_layers(input)\n",
    "        output_3a = self._3a(output_pl)\n",
    "        output_3b = self._3b(output_3a)\n",
    "        output_mp1 = self.maxpool(output_3b)\n",
    "        output_4a = self._4a(output_mp1)\n",
    "        output_4b = self._4b(output_4a)\n",
    "        output_4c = self._4c(output_4b)\n",
    "        output_4d = self._4d(output_4c)\n",
    "        output_4e = self._4e(output_4d)\n",
    "        output_mp2 = self.maxpool(output_4e)\n",
    "        output_5a = self._5a(output_mp2)\n",
    "        output_5b = self._5b(output_5a)\n",
    "        output_ap = self.avgpool(output_5b)\n",
    "        output_drop = self.dropout(output_ap)\n",
    "        output_ = output_drop.view(output_drop.size(0), -1)\n",
    "        output_ = self.linear(output_)\n",
    "        return output_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neural Network and Optimizer\n",
    "# We define neural net in model.py so that it can be reused by the evaluate.py script\n",
    "model = GoogLeNet().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=args.lr,weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    # This is an updated function which is not the one that used to train\n",
    "    # The one used to train in the following cell has a little bit of problem:\n",
    "    # I store the wrong value as the training_accuracy in the previous version\n",
    "    # That's why I cannot give the training_accuracy plot for this model\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        train_loss = F.cross_entropy(output,target).to(device)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), train_loss.item()))\n",
    "        pred = output.argmax(dim=1, keepdim=True)# get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        training_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "    return train_loss.item(), training_accuracy\n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        validation_loss += F.cross_entropy(output,target).to(device).item() # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)# get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    validation_accuracy = 100. * correct / len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.6f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset), validation_accuracy))\n",
    "    return validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an updated function which is not the one that used to train.  \n",
    "\n",
    "The one used to train in the following cell has a little bit of problem:\n",
    "\n",
    "I store the wrong value as the training_accuracy in the previous version.  \n",
    "\n",
    "That's why I cannot give the training_accuracy plot for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/35339 (0%)]\tLoss: 3.816276\n",
      "Train Epoch: 1 [6400/35339 (18%)]\tLoss: 2.370297\n",
      "Train Epoch: 1 [12800/35339 (36%)]\tLoss: 2.321045\n",
      "Train Epoch: 1 [19200/35339 (54%)]\tLoss: 1.324392\n",
      "Train Epoch: 1 [25600/35339 (72%)]\tLoss: 0.811110\n",
      "Train Epoch: 1 [32000/35339 (90%)]\tLoss: 0.518370\n",
      "\n",
      "Validation set: Average loss: 0.0325, Accuracy: 1676/3870 (43%)\n",
      "\n",
      "Train Epoch: 2 [0/35339 (0%)]\tLoss: 0.467572\n",
      "Train Epoch: 2 [6400/35339 (18%)]\tLoss: 0.261882\n",
      "Train Epoch: 2 [12800/35339 (36%)]\tLoss: 0.306955\n",
      "Train Epoch: 2 [19200/35339 (54%)]\tLoss: 0.200945\n",
      "Train Epoch: 2 [25600/35339 (72%)]\tLoss: 0.113898\n",
      "Train Epoch: 2 [32000/35339 (90%)]\tLoss: 0.143996\n",
      "\n",
      "Validation set: Average loss: 0.0157, Accuracy: 2713/3870 (70%)\n",
      "\n",
      "Train Epoch: 3 [0/35339 (0%)]\tLoss: 0.142094\n",
      "Train Epoch: 3 [6400/35339 (18%)]\tLoss: 0.049988\n",
      "Train Epoch: 3 [12800/35339 (36%)]\tLoss: 0.031888\n",
      "Train Epoch: 3 [19200/35339 (54%)]\tLoss: 0.048624\n",
      "Train Epoch: 3 [25600/35339 (72%)]\tLoss: 0.050247\n",
      "Train Epoch: 3 [32000/35339 (90%)]\tLoss: 0.040253\n",
      "\n",
      "Validation set: Average loss: 0.0109, Accuracy: 3155/3870 (82%)\n",
      "\n",
      "Train Epoch: 4 [0/35339 (0%)]\tLoss: 0.023451\n",
      "Train Epoch: 4 [6400/35339 (18%)]\tLoss: 0.023217\n",
      "Train Epoch: 4 [12800/35339 (36%)]\tLoss: 0.049565\n",
      "Train Epoch: 4 [19200/35339 (54%)]\tLoss: 0.053258\n",
      "Train Epoch: 4 [25600/35339 (72%)]\tLoss: 0.035576\n",
      "Train Epoch: 4 [32000/35339 (90%)]\tLoss: 0.012134\n",
      "\n",
      "Validation set: Average loss: 0.0104, Accuracy: 3172/3870 (82%)\n",
      "\n",
      "Train Epoch: 5 [0/35339 (0%)]\tLoss: 0.024090\n",
      "Train Epoch: 5 [6400/35339 (18%)]\tLoss: 0.022945\n",
      "Train Epoch: 5 [12800/35339 (36%)]\tLoss: 0.013375\n",
      "Train Epoch: 5 [19200/35339 (54%)]\tLoss: 0.014333\n",
      "Train Epoch: 5 [25600/35339 (72%)]\tLoss: 0.009728\n",
      "Train Epoch: 5 [32000/35339 (90%)]\tLoss: 0.026607\n",
      "\n",
      "Validation set: Average loss: 0.0089, Accuracy: 3290/3870 (85%)\n",
      "\n",
      "Train Epoch: 6 [0/35339 (0%)]\tLoss: 0.010088\n",
      "Train Epoch: 6 [6400/35339 (18%)]\tLoss: 0.024209\n",
      "Train Epoch: 6 [12800/35339 (36%)]\tLoss: 0.003555\n",
      "Train Epoch: 6 [19200/35339 (54%)]\tLoss: 0.011994\n",
      "Train Epoch: 6 [25600/35339 (72%)]\tLoss: 0.004487\n",
      "Train Epoch: 6 [32000/35339 (90%)]\tLoss: 0.008975\n",
      "\n",
      "Validation set: Average loss: 0.0067, Accuracy: 3389/3870 (88%)\n",
      "\n",
      "Train Epoch: 7 [0/35339 (0%)]\tLoss: 0.003480\n",
      "Train Epoch: 7 [6400/35339 (18%)]\tLoss: 0.009174\n",
      "Train Epoch: 7 [12800/35339 (36%)]\tLoss: 0.175283\n",
      "Train Epoch: 7 [19200/35339 (54%)]\tLoss: 0.007241\n",
      "Train Epoch: 7 [25600/35339 (72%)]\tLoss: 0.003509\n",
      "Train Epoch: 7 [32000/35339 (90%)]\tLoss: 0.009300\n",
      "\n",
      "Validation set: Average loss: 0.0078, Accuracy: 3354/3870 (87%)\n",
      "\n",
      "Train Epoch: 8 [0/35339 (0%)]\tLoss: 0.005194\n",
      "Train Epoch: 8 [6400/35339 (18%)]\tLoss: 0.022912\n",
      "Train Epoch: 8 [12800/35339 (36%)]\tLoss: 0.005188\n",
      "Train Epoch: 8 [19200/35339 (54%)]\tLoss: 0.008220\n",
      "Train Epoch: 8 [25600/35339 (72%)]\tLoss: 0.002999\n",
      "Train Epoch: 8 [32000/35339 (90%)]\tLoss: 0.002935\n",
      "\n",
      "Validation set: Average loss: 0.0148, Accuracy: 3173/3870 (82%)\n",
      "\n",
      "Train Epoch: 9 [0/35339 (0%)]\tLoss: 0.149293\n",
      "Train Epoch: 9 [6400/35339 (18%)]\tLoss: 0.001826\n",
      "Train Epoch: 9 [12800/35339 (36%)]\tLoss: 0.005076\n",
      "Train Epoch: 9 [19200/35339 (54%)]\tLoss: 0.021359\n",
      "Train Epoch: 9 [25600/35339 (72%)]\tLoss: 0.003526\n",
      "Train Epoch: 9 [32000/35339 (90%)]\tLoss: 0.002640\n",
      "\n",
      "Validation set: Average loss: 0.0063, Accuracy: 3464/3870 (90%)\n",
      "\n",
      "Train Epoch: 10 [0/35339 (0%)]\tLoss: 0.002787\n",
      "Train Epoch: 10 [6400/35339 (18%)]\tLoss: 0.001459\n",
      "Train Epoch: 10 [12800/35339 (36%)]\tLoss: 0.001535\n",
      "Train Epoch: 10 [19200/35339 (54%)]\tLoss: 0.001091\n",
      "Train Epoch: 10 [25600/35339 (72%)]\tLoss: 0.001203\n",
      "Train Epoch: 10 [32000/35339 (90%)]\tLoss: 0.001032\n",
      "\n",
      "Validation set: Average loss: 0.0081, Accuracy: 3393/3870 (88%)\n",
      "\n",
      "Train Epoch: 11 [0/35339 (0%)]\tLoss: 0.164205\n",
      "Train Epoch: 11 [6400/35339 (18%)]\tLoss: 0.064492\n",
      "Train Epoch: 11 [12800/35339 (36%)]\tLoss: 0.025434\n",
      "Train Epoch: 11 [19200/35339 (54%)]\tLoss: 0.047919\n",
      "Train Epoch: 11 [25600/35339 (72%)]\tLoss: 0.001449\n",
      "Train Epoch: 11 [32000/35339 (90%)]\tLoss: 0.051101\n",
      "\n",
      "Validation set: Average loss: 0.0064, Accuracy: 3451/3870 (89%)\n",
      "\n",
      "Train Epoch: 12 [0/35339 (0%)]\tLoss: 0.018456\n",
      "Train Epoch: 12 [6400/35339 (18%)]\tLoss: 0.003067\n",
      "Train Epoch: 12 [12800/35339 (36%)]\tLoss: 0.001887\n",
      "Train Epoch: 12 [19200/35339 (54%)]\tLoss: 0.001151\n",
      "Train Epoch: 12 [25600/35339 (72%)]\tLoss: 0.000363\n",
      "Train Epoch: 12 [32000/35339 (90%)]\tLoss: 0.000750\n",
      "\n",
      "Validation set: Average loss: 0.0051, Accuracy: 3568/3870 (92%)\n",
      "\n",
      "Train Epoch: 13 [0/35339 (0%)]\tLoss: 0.001613\n",
      "Train Epoch: 13 [6400/35339 (18%)]\tLoss: 0.009280\n",
      "Train Epoch: 13 [12800/35339 (36%)]\tLoss: 0.001000\n",
      "Train Epoch: 13 [19200/35339 (54%)]\tLoss: 0.003305\n",
      "Train Epoch: 13 [25600/35339 (72%)]\tLoss: 0.000739\n",
      "Train Epoch: 13 [32000/35339 (90%)]\tLoss: 0.000958\n",
      "\n",
      "Validation set: Average loss: 0.0035, Accuracy: 3633/3870 (94%)\n",
      "\n",
      "Train Epoch: 14 [0/35339 (0%)]\tLoss: 0.000681\n",
      "Train Epoch: 14 [6400/35339 (18%)]\tLoss: 0.000363\n",
      "Train Epoch: 14 [12800/35339 (36%)]\tLoss: 0.000357\n",
      "Train Epoch: 14 [19200/35339 (54%)]\tLoss: 0.005772\n",
      "Train Epoch: 14 [25600/35339 (72%)]\tLoss: 0.000549\n",
      "Train Epoch: 14 [32000/35339 (90%)]\tLoss: 0.002356\n",
      "\n",
      "Validation set: Average loss: 0.0047, Accuracy: 3547/3870 (92%)\n",
      "\n",
      "Train Epoch: 15 [0/35339 (0%)]\tLoss: 0.033678\n",
      "Train Epoch: 15 [6400/35339 (18%)]\tLoss: 0.000653\n",
      "Train Epoch: 15 [12800/35339 (36%)]\tLoss: 0.007357\n",
      "Train Epoch: 15 [19200/35339 (54%)]\tLoss: 0.003257\n",
      "Train Epoch: 15 [25600/35339 (72%)]\tLoss: 0.000982\n",
      "Train Epoch: 15 [32000/35339 (90%)]\tLoss: 0.012010\n",
      "\n",
      "Validation set: Average loss: 0.0050, Accuracy: 3564/3870 (92%)\n",
      "\n",
      "Train Epoch: 16 [0/35339 (0%)]\tLoss: 0.001276\n",
      "Train Epoch: 16 [6400/35339 (18%)]\tLoss: 0.006680\n",
      "Train Epoch: 16 [12800/35339 (36%)]\tLoss: 0.001775\n",
      "Train Epoch: 16 [19200/35339 (54%)]\tLoss: 0.000417\n",
      "Train Epoch: 16 [25600/35339 (72%)]\tLoss: 0.000433\n",
      "Train Epoch: 16 [32000/35339 (90%)]\tLoss: 0.004827\n",
      "\n",
      "Validation set: Average loss: 0.0036, Accuracy: 3626/3870 (94%)\n",
      "\n",
      "Train Epoch: 17 [0/35339 (0%)]\tLoss: 0.003972\n",
      "Train Epoch: 17 [6400/35339 (18%)]\tLoss: 0.000961\n",
      "Train Epoch: 17 [12800/35339 (36%)]\tLoss: 0.000982\n",
      "Train Epoch: 17 [19200/35339 (54%)]\tLoss: 0.000967\n",
      "Train Epoch: 17 [25600/35339 (72%)]\tLoss: 0.000831\n",
      "Train Epoch: 17 [32000/35339 (90%)]\tLoss: 0.001763\n",
      "\n",
      "Validation set: Average loss: 0.0040, Accuracy: 3626/3870 (94%)\n",
      "\n",
      "Train Epoch: 18 [0/35339 (0%)]\tLoss: 0.001167\n",
      "Train Epoch: 18 [6400/35339 (18%)]\tLoss: 0.002263\n",
      "Train Epoch: 18 [12800/35339 (36%)]\tLoss: 0.000228\n",
      "Train Epoch: 18 [19200/35339 (54%)]\tLoss: 0.001313\n",
      "Train Epoch: 18 [25600/35339 (72%)]\tLoss: 0.000383\n",
      "Train Epoch: 18 [32000/35339 (90%)]\tLoss: 0.000291\n",
      "\n",
      "Validation set: Average loss: 0.0037, Accuracy: 3664/3870 (95%)\n",
      "\n",
      "Train Epoch: 19 [0/35339 (0%)]\tLoss: 0.000734\n",
      "Train Epoch: 19 [6400/35339 (18%)]\tLoss: 0.000224\n",
      "Train Epoch: 19 [12800/35339 (36%)]\tLoss: 0.000158\n",
      "Train Epoch: 19 [19200/35339 (54%)]\tLoss: 0.001779\n",
      "Train Epoch: 19 [25600/35339 (72%)]\tLoss: 0.000281\n",
      "Train Epoch: 19 [32000/35339 (90%)]\tLoss: 0.000296\n",
      "\n",
      "Validation set: Average loss: 0.0030, Accuracy: 3665/3870 (95%)\n",
      "\n",
      "Train Epoch: 20 [0/35339 (0%)]\tLoss: 0.000244\n",
      "Train Epoch: 20 [6400/35339 (18%)]\tLoss: 0.103402\n",
      "Train Epoch: 20 [12800/35339 (36%)]\tLoss: 0.000870\n",
      "Train Epoch: 20 [19200/35339 (54%)]\tLoss: 0.000465\n",
      "Train Epoch: 20 [25600/35339 (72%)]\tLoss: 0.000494\n",
      "Train Epoch: 20 [32000/35339 (90%)]\tLoss: 0.000785\n",
      "\n",
      "Validation set: Average loss: 0.0027, Accuracy: 3689/3870 (95%)\n",
      "\n",
      "Train Epoch: 21 [0/35339 (0%)]\tLoss: 0.023220\n",
      "Train Epoch: 21 [6400/35339 (18%)]\tLoss: 0.001054\n",
      "Train Epoch: 21 [12800/35339 (36%)]\tLoss: 0.159880\n",
      "Train Epoch: 21 [19200/35339 (54%)]\tLoss: 0.001101\n",
      "Train Epoch: 21 [25600/35339 (72%)]\tLoss: 0.000652\n",
      "Train Epoch: 21 [32000/35339 (90%)]\tLoss: 0.000755\n",
      "\n",
      "Validation set: Average loss: 0.0023, Accuracy: 3718/3870 (96%)\n",
      "\n",
      "Train Epoch: 22 [0/35339 (0%)]\tLoss: 0.007409\n",
      "Train Epoch: 22 [6400/35339 (18%)]\tLoss: 0.000549\n",
      "Train Epoch: 22 [12800/35339 (36%)]\tLoss: 0.000240\n",
      "Train Epoch: 22 [19200/35339 (54%)]\tLoss: 0.000271\n",
      "Train Epoch: 22 [25600/35339 (72%)]\tLoss: 0.000620\n",
      "Train Epoch: 22 [32000/35339 (90%)]\tLoss: 0.003045\n",
      "\n",
      "Validation set: Average loss: 0.0022, Accuracy: 3723/3870 (96%)\n",
      "\n",
      "Train Epoch: 23 [0/35339 (0%)]\tLoss: 0.000182\n",
      "Train Epoch: 23 [6400/35339 (18%)]\tLoss: 0.001822\n",
      "Train Epoch: 23 [12800/35339 (36%)]\tLoss: 0.003862\n",
      "Train Epoch: 23 [19200/35339 (54%)]\tLoss: 0.000356\n",
      "Train Epoch: 23 [25600/35339 (72%)]\tLoss: 0.000321\n",
      "Train Epoch: 23 [32000/35339 (90%)]\tLoss: 0.000096\n",
      "\n",
      "Validation set: Average loss: 0.0018, Accuracy: 3742/3870 (97%)\n",
      "\n",
      "Train Epoch: 24 [0/35339 (0%)]\tLoss: 0.000290\n",
      "Train Epoch: 24 [6400/35339 (18%)]\tLoss: 0.000374\n",
      "Train Epoch: 24 [12800/35339 (36%)]\tLoss: 0.004925\n",
      "Train Epoch: 24 [19200/35339 (54%)]\tLoss: 0.000206\n",
      "Train Epoch: 24 [25600/35339 (72%)]\tLoss: 0.000585\n",
      "Train Epoch: 24 [32000/35339 (90%)]\tLoss: 0.000212\n",
      "\n",
      "Validation set: Average loss: 0.0021, Accuracy: 3716/3870 (96%)\n",
      "\n",
      "Train Epoch: 25 [0/35339 (0%)]\tLoss: 0.000161\n",
      "Train Epoch: 25 [6400/35339 (18%)]\tLoss: 0.000208\n",
      "Train Epoch: 25 [12800/35339 (36%)]\tLoss: 0.000319\n",
      "Train Epoch: 25 [19200/35339 (54%)]\tLoss: 0.000183\n",
      "Train Epoch: 25 [25600/35339 (72%)]\tLoss: 0.000081\n",
      "Train Epoch: 25 [32000/35339 (90%)]\tLoss: 0.000087\n",
      "\n",
      "Validation set: Average loss: 0.0020, Accuracy: 3731/3870 (96%)\n",
      "\n",
      "Train Epoch: 26 [0/35339 (0%)]\tLoss: 0.000095\n",
      "Train Epoch: 26 [6400/35339 (18%)]\tLoss: 0.000185\n",
      "Train Epoch: 26 [12800/35339 (36%)]\tLoss: 0.000170\n",
      "Train Epoch: 26 [19200/35339 (54%)]\tLoss: 0.000059\n",
      "Train Epoch: 26 [25600/35339 (72%)]\tLoss: 0.000034\n",
      "Train Epoch: 26 [32000/35339 (90%)]\tLoss: 0.000191\n",
      "\n",
      "Validation set: Average loss: 0.0021, Accuracy: 3726/3870 (96%)\n",
      "\n",
      "Train Epoch: 27 [0/35339 (0%)]\tLoss: 0.000058\n",
      "Train Epoch: 27 [6400/35339 (18%)]\tLoss: 0.000042\n",
      "Train Epoch: 27 [12800/35339 (36%)]\tLoss: 0.000045\n",
      "Train Epoch: 27 [19200/35339 (54%)]\tLoss: 0.000050\n",
      "Train Epoch: 27 [25600/35339 (72%)]\tLoss: 0.000036\n",
      "Train Epoch: 27 [32000/35339 (90%)]\tLoss: 0.000056\n",
      "\n",
      "Validation set: Average loss: 0.0018, Accuracy: 3738/3870 (97%)\n",
      "\n",
      "Train Epoch: 28 [0/35339 (0%)]\tLoss: 0.000044\n",
      "Train Epoch: 28 [6400/35339 (18%)]\tLoss: 0.000044\n",
      "Train Epoch: 28 [12800/35339 (36%)]\tLoss: 0.000035\n",
      "Train Epoch: 28 [19200/35339 (54%)]\tLoss: 0.000041\n",
      "Train Epoch: 28 [25600/35339 (72%)]\tLoss: 0.000039\n",
      "Train Epoch: 28 [32000/35339 (90%)]\tLoss: 0.000048\n",
      "\n",
      "Validation set: Average loss: 0.0018, Accuracy: 3734/3870 (96%)\n",
      "\n",
      "Train Epoch: 29 [0/35339 (0%)]\tLoss: 0.000041\n",
      "Train Epoch: 29 [6400/35339 (18%)]\tLoss: 0.021778\n",
      "Train Epoch: 29 [12800/35339 (36%)]\tLoss: 0.012275\n",
      "Train Epoch: 29 [19200/35339 (54%)]\tLoss: 0.000732\n",
      "Train Epoch: 29 [25600/35339 (72%)]\tLoss: 0.001493\n",
      "Train Epoch: 29 [32000/35339 (90%)]\tLoss: 0.001397\n",
      "\n",
      "Validation set: Average loss: 0.0016, Accuracy: 3747/3870 (97%)\n",
      "\n",
      "Train Epoch: 30 [0/35339 (0%)]\tLoss: 0.000337\n",
      "Train Epoch: 30 [6400/35339 (18%)]\tLoss: 0.000207\n",
      "Train Epoch: 30 [12800/35339 (36%)]\tLoss: 0.002084\n",
      "Train Epoch: 30 [19200/35339 (54%)]\tLoss: 0.000371\n",
      "Train Epoch: 30 [25600/35339 (72%)]\tLoss: 0.000310\n",
      "Train Epoch: 30 [32000/35339 (90%)]\tLoss: 0.001326\n",
      "\n",
      "Validation set: Average loss: 0.0019, Accuracy: 3734/3870 (96%)\n",
      "\n",
      "Train Epoch: 31 [0/35339 (0%)]\tLoss: 0.000338\n",
      "Train Epoch: 31 [6400/35339 (18%)]\tLoss: 0.002363\n",
      "Train Epoch: 31 [12800/35339 (36%)]\tLoss: 0.001380\n",
      "Train Epoch: 31 [19200/35339 (54%)]\tLoss: 0.000911\n",
      "Train Epoch: 31 [25600/35339 (72%)]\tLoss: 0.000287\n",
      "Train Epoch: 31 [32000/35339 (90%)]\tLoss: 0.001654\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3794/3870 (98%)\n",
      "\n",
      "Train Epoch: 32 [0/35339 (0%)]\tLoss: 0.000155\n",
      "Train Epoch: 32 [6400/35339 (18%)]\tLoss: 0.000080\n",
      "Train Epoch: 32 [12800/35339 (36%)]\tLoss: 0.000128\n",
      "Train Epoch: 32 [19200/35339 (54%)]\tLoss: 0.000152\n",
      "Train Epoch: 32 [25600/35339 (72%)]\tLoss: 0.000034\n",
      "Train Epoch: 32 [32000/35339 (90%)]\tLoss: 0.000128\n",
      "\n",
      "Validation set: Average loss: 0.0007, Accuracy: 3823/3870 (99%)\n",
      "\n",
      "Train Epoch: 33 [0/35339 (0%)]\tLoss: 0.000034\n",
      "Train Epoch: 33 [6400/35339 (18%)]\tLoss: 0.000039\n",
      "Train Epoch: 33 [12800/35339 (36%)]\tLoss: 0.000237\n",
      "Train Epoch: 33 [19200/35339 (54%)]\tLoss: 0.000053\n",
      "Train Epoch: 33 [25600/35339 (72%)]\tLoss: 0.001152\n",
      "Train Epoch: 33 [32000/35339 (90%)]\tLoss: 0.001093\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3797/3870 (98%)\n",
      "\n",
      "Train Epoch: 34 [0/35339 (0%)]\tLoss: 0.000324\n",
      "Train Epoch: 34 [6400/35339 (18%)]\tLoss: 0.000145\n",
      "Train Epoch: 34 [12800/35339 (36%)]\tLoss: 0.000195\n",
      "Train Epoch: 34 [19200/35339 (54%)]\tLoss: 0.000083\n",
      "Train Epoch: 34 [25600/35339 (72%)]\tLoss: 0.000144\n",
      "Train Epoch: 34 [32000/35339 (90%)]\tLoss: 0.000053\n",
      "\n",
      "Validation set: Average loss: 0.0013, Accuracy: 3786/3870 (98%)\n",
      "\n",
      "Train Epoch: 35 [0/35339 (0%)]\tLoss: 0.000205\n",
      "Train Epoch: 35 [6400/35339 (18%)]\tLoss: 0.000273\n",
      "Train Epoch: 35 [12800/35339 (36%)]\tLoss: 0.000125\n",
      "Train Epoch: 35 [19200/35339 (54%)]\tLoss: 0.000125\n",
      "Train Epoch: 35 [25600/35339 (72%)]\tLoss: 0.000088\n",
      "Train Epoch: 35 [32000/35339 (90%)]\tLoss: 0.000076\n",
      "\n",
      "Validation set: Average loss: 0.0019, Accuracy: 3745/3870 (97%)\n",
      "\n",
      "Train Epoch: 36 [0/35339 (0%)]\tLoss: 0.000059\n",
      "Train Epoch: 36 [6400/35339 (18%)]\tLoss: 0.000223\n",
      "Train Epoch: 36 [12800/35339 (36%)]\tLoss: 0.000050\n",
      "Train Epoch: 36 [19200/35339 (54%)]\tLoss: 0.000081\n",
      "Train Epoch: 36 [25600/35339 (72%)]\tLoss: 0.000093\n",
      "Train Epoch: 36 [32000/35339 (90%)]\tLoss: 0.000089\n",
      "\n",
      "Validation set: Average loss: 0.0019, Accuracy: 3730/3870 (96%)\n",
      "\n",
      "Train Epoch: 37 [0/35339 (0%)]\tLoss: 0.000300\n",
      "Train Epoch: 37 [6400/35339 (18%)]\tLoss: 0.000177\n",
      "Train Epoch: 37 [12800/35339 (36%)]\tLoss: 0.002861\n",
      "Train Epoch: 37 [19200/35339 (54%)]\tLoss: 0.003345\n",
      "Train Epoch: 37 [25600/35339 (72%)]\tLoss: 0.000565\n",
      "Train Epoch: 37 [32000/35339 (90%)]\tLoss: 0.000966\n",
      "\n",
      "Validation set: Average loss: 0.0072, Accuracy: 3507/3870 (91%)\n",
      "\n",
      "Train Epoch: 38 [0/35339 (0%)]\tLoss: 0.036477\n",
      "Train Epoch: 38 [6400/35339 (18%)]\tLoss: 0.000319\n",
      "Train Epoch: 38 [12800/35339 (36%)]\tLoss: 0.000239\n",
      "Train Epoch: 38 [19200/35339 (54%)]\tLoss: 0.000476\n",
      "Train Epoch: 38 [25600/35339 (72%)]\tLoss: 0.000047\n",
      "Train Epoch: 38 [32000/35339 (90%)]\tLoss: 0.000131\n",
      "\n",
      "Validation set: Average loss: 0.0010, Accuracy: 3784/3870 (98%)\n",
      "\n",
      "Train Epoch: 39 [0/35339 (0%)]\tLoss: 0.000071\n",
      "Train Epoch: 39 [6400/35339 (18%)]\tLoss: 0.000058\n",
      "Train Epoch: 39 [12800/35339 (36%)]\tLoss: 0.000061\n",
      "Train Epoch: 39 [19200/35339 (54%)]\tLoss: 0.000148\n",
      "Train Epoch: 39 [25600/35339 (72%)]\tLoss: 0.000173\n",
      "Train Epoch: 39 [32000/35339 (90%)]\tLoss: 0.000098\n",
      "\n",
      "Validation set: Average loss: 0.0011, Accuracy: 3777/3870 (98%)\n",
      "\n",
      "Train Epoch: 40 [0/35339 (0%)]\tLoss: 0.000147\n",
      "Train Epoch: 40 [6400/35339 (18%)]\tLoss: 0.376543\n",
      "Train Epoch: 40 [12800/35339 (36%)]\tLoss: 0.000428\n",
      "Train Epoch: 40 [19200/35339 (54%)]\tLoss: 0.000274\n",
      "Train Epoch: 40 [25600/35339 (72%)]\tLoss: 0.001369\n",
      "Train Epoch: 40 [32000/35339 (90%)]\tLoss: 0.000296\n",
      "\n",
      "Validation set: Average loss: 0.0013, Accuracy: 3770/3870 (97%)\n",
      "\n",
      "Train Epoch: 41 [0/35339 (0%)]\tLoss: 0.000456\n",
      "Train Epoch: 41 [6400/35339 (18%)]\tLoss: 0.000219\n",
      "Train Epoch: 41 [12800/35339 (36%)]\tLoss: 0.000051\n",
      "Train Epoch: 41 [19200/35339 (54%)]\tLoss: 0.000075\n",
      "Train Epoch: 41 [25600/35339 (72%)]\tLoss: 0.000126\n",
      "Train Epoch: 41 [32000/35339 (90%)]\tLoss: 0.000581\n",
      "\n",
      "Validation set: Average loss: 0.0013, Accuracy: 3776/3870 (98%)\n",
      "\n",
      "Train Epoch: 42 [0/35339 (0%)]\tLoss: 0.000031\n",
      "Train Epoch: 42 [6400/35339 (18%)]\tLoss: 0.000186\n",
      "Train Epoch: 42 [12800/35339 (36%)]\tLoss: 0.007781\n",
      "Train Epoch: 42 [19200/35339 (54%)]\tLoss: 0.000081\n",
      "Train Epoch: 42 [25600/35339 (72%)]\tLoss: 0.000267\n",
      "Train Epoch: 42 [32000/35339 (90%)]\tLoss: 0.000066\n",
      "\n",
      "Validation set: Average loss: 0.0006, Accuracy: 3822/3870 (99%)\n",
      "\n",
      "Train Epoch: 43 [0/35339 (0%)]\tLoss: 0.000223\n",
      "Train Epoch: 43 [6400/35339 (18%)]\tLoss: 0.012574\n",
      "Train Epoch: 43 [12800/35339 (36%)]\tLoss: 0.000097\n",
      "Train Epoch: 43 [19200/35339 (54%)]\tLoss: 0.000101\n",
      "Train Epoch: 43 [25600/35339 (72%)]\tLoss: 0.016448\n",
      "Train Epoch: 43 [32000/35339 (90%)]\tLoss: 0.000417\n",
      "\n",
      "Validation set: Average loss: 0.0010, Accuracy: 3791/3870 (98%)\n",
      "\n",
      "Train Epoch: 44 [0/35339 (0%)]\tLoss: 0.000052\n",
      "Train Epoch: 44 [6400/35339 (18%)]\tLoss: 0.000068\n",
      "Train Epoch: 44 [12800/35339 (36%)]\tLoss: 0.000252\n",
      "Train Epoch: 44 [19200/35339 (54%)]\tLoss: 0.000369\n",
      "Train Epoch: 44 [25600/35339 (72%)]\tLoss: 0.000052\n",
      "Train Epoch: 44 [32000/35339 (90%)]\tLoss: 0.000052\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3804/3870 (98%)\n",
      "\n",
      "Train Epoch: 45 [0/35339 (0%)]\tLoss: 0.000037\n",
      "Train Epoch: 45 [6400/35339 (18%)]\tLoss: 0.000022\n",
      "Train Epoch: 45 [12800/35339 (36%)]\tLoss: 0.000025\n",
      "Train Epoch: 45 [19200/35339 (54%)]\tLoss: 0.000016\n",
      "Train Epoch: 45 [25600/35339 (72%)]\tLoss: 0.000042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 45 [32000/35339 (90%)]\tLoss: 0.000037\n",
      "\n",
      "Validation set: Average loss: 0.0007, Accuracy: 3812/3870 (99%)\n",
      "\n",
      "Train Epoch: 46 [0/35339 (0%)]\tLoss: 0.000043\n",
      "Train Epoch: 46 [6400/35339 (18%)]\tLoss: 0.000023\n",
      "Train Epoch: 46 [12800/35339 (36%)]\tLoss: 0.000017\n",
      "Train Epoch: 46 [19200/35339 (54%)]\tLoss: 0.000014\n",
      "Train Epoch: 46 [25600/35339 (72%)]\tLoss: 0.000045\n",
      "Train Epoch: 46 [32000/35339 (90%)]\tLoss: 0.000014\n",
      "\n",
      "Validation set: Average loss: 0.0007, Accuracy: 3813/3870 (99%)\n",
      "\n",
      "Train Epoch: 47 [0/35339 (0%)]\tLoss: 0.000021\n",
      "Train Epoch: 47 [6400/35339 (18%)]\tLoss: 0.000014\n",
      "Train Epoch: 47 [12800/35339 (36%)]\tLoss: 0.000029\n",
      "Train Epoch: 47 [19200/35339 (54%)]\tLoss: 0.000025\n",
      "Train Epoch: 47 [25600/35339 (72%)]\tLoss: 0.000006\n",
      "Train Epoch: 47 [32000/35339 (90%)]\tLoss: 0.000004\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3812/3870 (99%)\n",
      "\n",
      "Train Epoch: 48 [0/35339 (0%)]\tLoss: 0.000014\n",
      "Train Epoch: 48 [6400/35339 (18%)]\tLoss: 0.002355\n",
      "Train Epoch: 48 [12800/35339 (36%)]\tLoss: 0.000258\n",
      "Train Epoch: 48 [19200/35339 (54%)]\tLoss: 0.000269\n",
      "Train Epoch: 48 [25600/35339 (72%)]\tLoss: 0.000268\n",
      "Train Epoch: 48 [32000/35339 (90%)]\tLoss: 0.001324\n",
      "\n",
      "Validation set: Average loss: 0.0018, Accuracy: 3744/3870 (97%)\n",
      "\n",
      "Train Epoch: 49 [0/35339 (0%)]\tLoss: 0.000361\n",
      "Train Epoch: 49 [6400/35339 (18%)]\tLoss: 0.000112\n",
      "Train Epoch: 49 [12800/35339 (36%)]\tLoss: 0.000104\n",
      "Train Epoch: 49 [19200/35339 (54%)]\tLoss: 0.000089\n",
      "Train Epoch: 49 [25600/35339 (72%)]\tLoss: 0.000041\n",
      "Train Epoch: 49 [32000/35339 (90%)]\tLoss: 0.000042\n",
      "\n",
      "Validation set: Average loss: 0.0010, Accuracy: 3797/3870 (98%)\n",
      "\n",
      "Train Epoch: 50 [0/35339 (0%)]\tLoss: 0.000083\n",
      "Train Epoch: 50 [6400/35339 (18%)]\tLoss: 0.000021\n",
      "Train Epoch: 50 [12800/35339 (36%)]\tLoss: 0.000054\n",
      "Train Epoch: 50 [19200/35339 (54%)]\tLoss: 0.000119\n",
      "Train Epoch: 50 [25600/35339 (72%)]\tLoss: 0.000067\n",
      "Train Epoch: 50 [32000/35339 (90%)]\tLoss: 0.000021\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3810/3870 (98%)\n",
      "\n",
      "Train Epoch: 51 [0/35339 (0%)]\tLoss: 0.000035\n",
      "Train Epoch: 51 [6400/35339 (18%)]\tLoss: 0.000016\n",
      "Train Epoch: 51 [12800/35339 (36%)]\tLoss: 0.000009\n",
      "Train Epoch: 51 [19200/35339 (54%)]\tLoss: 0.000020\n",
      "Train Epoch: 51 [25600/35339 (72%)]\tLoss: 0.000023\n",
      "Train Epoch: 51 [32000/35339 (90%)]\tLoss: 0.000015\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3808/3870 (98%)\n",
      "\n",
      "Train Epoch: 52 [0/35339 (0%)]\tLoss: 0.000023\n",
      "Train Epoch: 52 [6400/35339 (18%)]\tLoss: 0.000022\n",
      "Train Epoch: 52 [12800/35339 (36%)]\tLoss: 0.000015\n",
      "Train Epoch: 52 [19200/35339 (54%)]\tLoss: 0.000008\n",
      "Train Epoch: 52 [25600/35339 (72%)]\tLoss: 0.000032\n",
      "Train Epoch: 52 [32000/35339 (90%)]\tLoss: 0.000007\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3808/3870 (98%)\n",
      "\n",
      "Train Epoch: 53 [0/35339 (0%)]\tLoss: 0.000026\n",
      "Train Epoch: 53 [6400/35339 (18%)]\tLoss: 0.000021\n",
      "Train Epoch: 53 [12800/35339 (36%)]\tLoss: 0.000013\n",
      "Train Epoch: 53 [19200/35339 (54%)]\tLoss: 0.049426\n",
      "Train Epoch: 53 [25600/35339 (72%)]\tLoss: 0.000743\n",
      "Train Epoch: 53 [32000/35339 (90%)]\tLoss: 0.000489\n",
      "\n",
      "Validation set: Average loss: 0.0010, Accuracy: 3791/3870 (98%)\n",
      "\n",
      "Train Epoch: 54 [0/35339 (0%)]\tLoss: 0.005305\n",
      "Train Epoch: 54 [6400/35339 (18%)]\tLoss: 0.000232\n",
      "Train Epoch: 54 [12800/35339 (36%)]\tLoss: 0.000418\n",
      "Train Epoch: 54 [19200/35339 (54%)]\tLoss: 0.000268\n",
      "Train Epoch: 54 [25600/35339 (72%)]\tLoss: 0.000070\n",
      "Train Epoch: 54 [32000/35339 (90%)]\tLoss: 0.000095\n",
      "\n",
      "Validation set: Average loss: 0.0006, Accuracy: 3814/3870 (99%)\n",
      "\n",
      "Train Epoch: 55 [0/35339 (0%)]\tLoss: 0.000068\n",
      "Train Epoch: 55 [6400/35339 (18%)]\tLoss: 0.000061\n",
      "Train Epoch: 55 [12800/35339 (36%)]\tLoss: 0.000056\n",
      "Train Epoch: 55 [19200/35339 (54%)]\tLoss: 0.000085\n",
      "Train Epoch: 55 [25600/35339 (72%)]\tLoss: 0.000043\n",
      "Train Epoch: 55 [32000/35339 (90%)]\tLoss: 0.001378\n",
      "\n",
      "Validation set: Average loss: 0.0004, Accuracy: 3836/3870 (99%)\n",
      "\n",
      "Train Epoch: 56 [0/35339 (0%)]\tLoss: 0.000104\n",
      "Train Epoch: 56 [6400/35339 (18%)]\tLoss: 0.000067\n",
      "Train Epoch: 56 [12800/35339 (36%)]\tLoss: 0.000039\n",
      "Train Epoch: 56 [19200/35339 (54%)]\tLoss: 0.000040\n",
      "Train Epoch: 56 [25600/35339 (72%)]\tLoss: 0.000204\n",
      "Train Epoch: 56 [32000/35339 (90%)]\tLoss: 0.000034\n",
      "\n",
      "Validation set: Average loss: 0.0004, Accuracy: 3845/3870 (99%)\n",
      "\n",
      "Train Epoch: 57 [0/35339 (0%)]\tLoss: 0.000022\n",
      "Train Epoch: 57 [6400/35339 (18%)]\tLoss: 0.000019\n",
      "Train Epoch: 57 [12800/35339 (36%)]\tLoss: 0.000022\n",
      "Train Epoch: 57 [19200/35339 (54%)]\tLoss: 0.000055\n",
      "Train Epoch: 57 [25600/35339 (72%)]\tLoss: 0.000069\n",
      "Train Epoch: 57 [32000/35339 (90%)]\tLoss: 0.000017\n",
      "\n",
      "Validation set: Average loss: 0.0003, Accuracy: 3843/3870 (99%)\n",
      "\n",
      "Train Epoch: 58 [0/35339 (0%)]\tLoss: 0.000011\n",
      "Train Epoch: 58 [6400/35339 (18%)]\tLoss: 0.000014\n",
      "Train Epoch: 58 [12800/35339 (36%)]\tLoss: 0.000051\n",
      "Train Epoch: 58 [19200/35339 (54%)]\tLoss: 0.000042\n",
      "Train Epoch: 58 [25600/35339 (72%)]\tLoss: 0.000012\n",
      "Train Epoch: 58 [32000/35339 (90%)]\tLoss: 0.000024\n",
      "\n",
      "Validation set: Average loss: 0.0003, Accuracy: 3848/3870 (99%)\n",
      "\n",
      "Train Epoch: 59 [0/35339 (0%)]\tLoss: 0.000046\n",
      "Train Epoch: 59 [6400/35339 (18%)]\tLoss: 0.000060\n",
      "Train Epoch: 59 [12800/35339 (36%)]\tLoss: 0.000027\n",
      "Train Epoch: 59 [19200/35339 (54%)]\tLoss: 0.000019\n",
      "Train Epoch: 59 [25600/35339 (72%)]\tLoss: 0.000026\n",
      "Train Epoch: 59 [32000/35339 (90%)]\tLoss: 0.000030\n",
      "\n",
      "Validation set: Average loss: 0.0003, Accuracy: 3845/3870 (99%)\n",
      "\n",
      "Train Epoch: 60 [0/35339 (0%)]\tLoss: 0.000042\n",
      "Train Epoch: 60 [6400/35339 (18%)]\tLoss: 0.000024\n",
      "Train Epoch: 60 [12800/35339 (36%)]\tLoss: 0.000010\n",
      "Train Epoch: 60 [19200/35339 (54%)]\tLoss: 0.000042\n",
      "Train Epoch: 60 [25600/35339 (72%)]\tLoss: 0.000005\n",
      "Train Epoch: 60 [32000/35339 (90%)]\tLoss: 0.000033\n",
      "\n",
      "Validation set: Average loss: 0.0003, Accuracy: 3840/3870 (99%)\n",
      "\n",
      "Train Epoch: 61 [0/35339 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 61 [6400/35339 (18%)]\tLoss: 0.000005\n",
      "Train Epoch: 61 [12800/35339 (36%)]\tLoss: 0.000005\n",
      "Train Epoch: 61 [19200/35339 (54%)]\tLoss: 0.000028\n",
      "Train Epoch: 61 [25600/35339 (72%)]\tLoss: 0.000008\n",
      "Train Epoch: 61 [32000/35339 (90%)]\tLoss: 0.000013\n",
      "\n",
      "Validation set: Average loss: 0.0002, Accuracy: 3849/3870 (99%)\n",
      "\n",
      "Train Epoch: 62 [0/35339 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 62 [6400/35339 (18%)]\tLoss: 0.000015\n",
      "Train Epoch: 62 [12800/35339 (36%)]\tLoss: 0.000005\n",
      "Train Epoch: 62 [19200/35339 (54%)]\tLoss: 0.000003\n",
      "Train Epoch: 62 [25600/35339 (72%)]\tLoss: 0.000004\n",
      "Train Epoch: 62 [32000/35339 (90%)]\tLoss: 0.000008\n",
      "\n",
      "Validation set: Average loss: 0.0003, Accuracy: 3845/3870 (99%)\n",
      "\n",
      "Train Epoch: 63 [0/35339 (0%)]\tLoss: 0.000019\n",
      "Train Epoch: 63 [6400/35339 (18%)]\tLoss: 0.000002\n",
      "Train Epoch: 63 [12800/35339 (36%)]\tLoss: 0.000003\n",
      "Train Epoch: 63 [19200/35339 (54%)]\tLoss: 0.000005\n",
      "Train Epoch: 63 [25600/35339 (72%)]\tLoss: 0.000016\n",
      "Train Epoch: 63 [32000/35339 (90%)]\tLoss: 0.000003\n",
      "\n",
      "Validation set: Average loss: 0.0003, Accuracy: 3847/3870 (99%)\n",
      "\n",
      "Train Epoch: 64 [0/35339 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 64 [6400/35339 (18%)]\tLoss: 0.000005\n",
      "Train Epoch: 64 [12800/35339 (36%)]\tLoss: 0.031505\n",
      "Train Epoch: 64 [19200/35339 (54%)]\tLoss: 0.007991\n",
      "Train Epoch: 64 [25600/35339 (72%)]\tLoss: 0.000274\n",
      "Train Epoch: 64 [32000/35339 (90%)]\tLoss: 0.000199\n",
      "\n",
      "Validation set: Average loss: 0.0011, Accuracy: 3787/3870 (98%)\n",
      "\n",
      "Train Epoch: 65 [0/35339 (0%)]\tLoss: 0.000127\n",
      "Train Epoch: 65 [6400/35339 (18%)]\tLoss: 0.000080\n",
      "Train Epoch: 65 [12800/35339 (36%)]\tLoss: 0.000049\n",
      "Train Epoch: 65 [19200/35339 (54%)]\tLoss: 0.000026\n",
      "Train Epoch: 65 [25600/35339 (72%)]\tLoss: 0.000040\n",
      "Train Epoch: 65 [32000/35339 (90%)]\tLoss: 0.000028\n",
      "\n",
      "Validation set: Average loss: 0.0011, Accuracy: 3792/3870 (98%)\n",
      "\n",
      "Train Epoch: 66 [0/35339 (0%)]\tLoss: 0.000043\n",
      "Train Epoch: 66 [6400/35339 (18%)]\tLoss: 0.000014\n",
      "Train Epoch: 66 [12800/35339 (36%)]\tLoss: 0.000036\n",
      "Train Epoch: 66 [19200/35339 (54%)]\tLoss: 0.000032\n",
      "Train Epoch: 66 [25600/35339 (72%)]\tLoss: 0.000101\n",
      "Train Epoch: 66 [32000/35339 (90%)]\tLoss: 0.000009\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3811/3870 (98%)\n",
      "\n",
      "Train Epoch: 67 [0/35339 (0%)]\tLoss: 0.000422\n",
      "Train Epoch: 67 [6400/35339 (18%)]\tLoss: 0.000061\n",
      "Train Epoch: 67 [12800/35339 (36%)]\tLoss: 0.000007\n",
      "Train Epoch: 67 [19200/35339 (54%)]\tLoss: 0.000010\n",
      "Train Epoch: 67 [25600/35339 (72%)]\tLoss: 0.000014\n",
      "Train Epoch: 67 [32000/35339 (90%)]\tLoss: 0.000007\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3814/3870 (99%)\n",
      "\n",
      "Train Epoch: 68 [0/35339 (0%)]\tLoss: 0.000009\n",
      "Train Epoch: 68 [6400/35339 (18%)]\tLoss: 0.000014\n",
      "Train Epoch: 68 [12800/35339 (36%)]\tLoss: 0.000014\n",
      "Train Epoch: 68 [19200/35339 (54%)]\tLoss: 0.000047\n",
      "Train Epoch: 68 [25600/35339 (72%)]\tLoss: 0.000022\n",
      "Train Epoch: 68 [32000/35339 (90%)]\tLoss: 0.000102\n",
      "\n",
      "Validation set: Average loss: 0.0007, Accuracy: 3820/3870 (99%)\n",
      "\n",
      "Train Epoch: 69 [0/35339 (0%)]\tLoss: 0.000025\n",
      "Train Epoch: 69 [6400/35339 (18%)]\tLoss: 0.000021\n",
      "Train Epoch: 69 [12800/35339 (36%)]\tLoss: 0.000009\n",
      "Train Epoch: 69 [19200/35339 (54%)]\tLoss: 0.000009\n",
      "Train Epoch: 69 [25600/35339 (72%)]\tLoss: 0.000013\n",
      "Train Epoch: 69 [32000/35339 (90%)]\tLoss: 0.000027\n",
      "\n",
      "Validation set: Average loss: 0.0006, Accuracy: 3824/3870 (99%)\n",
      "\n",
      "Train Epoch: 70 [0/35339 (0%)]\tLoss: 0.000058\n",
      "Train Epoch: 70 [6400/35339 (18%)]\tLoss: 0.000010\n",
      "Train Epoch: 70 [12800/35339 (36%)]\tLoss: 0.000035\n",
      "Train Epoch: 70 [19200/35339 (54%)]\tLoss: 0.000019\n",
      "Train Epoch: 70 [25600/35339 (72%)]\tLoss: 0.000007\n",
      "Train Epoch: 70 [32000/35339 (90%)]\tLoss: 0.000013\n",
      "\n",
      "Validation set: Average loss: 0.0007, Accuracy: 3823/3870 (99%)\n",
      "\n",
      "Train Epoch: 71 [0/35339 (0%)]\tLoss: 0.000005\n",
      "Train Epoch: 71 [6400/35339 (18%)]\tLoss: 0.000010\n",
      "Train Epoch: 71 [12800/35339 (36%)]\tLoss: 0.000010\n",
      "Train Epoch: 71 [19200/35339 (54%)]\tLoss: 0.000007\n",
      "Train Epoch: 71 [25600/35339 (72%)]\tLoss: 0.000006\n",
      "Train Epoch: 71 [32000/35339 (90%)]\tLoss: 0.130843\n",
      "\n",
      "Validation set: Average loss: 0.0019, Accuracy: 3732/3870 (96%)\n",
      "\n",
      "Train Epoch: 72 [0/35339 (0%)]\tLoss: 0.006376\n",
      "Train Epoch: 72 [6400/35339 (18%)]\tLoss: 0.000219\n",
      "Train Epoch: 72 [12800/35339 (36%)]\tLoss: 0.000113\n",
      "Train Epoch: 72 [19200/35339 (54%)]\tLoss: 0.000222\n",
      "Train Epoch: 72 [25600/35339 (72%)]\tLoss: 0.000061\n",
      "Train Epoch: 72 [32000/35339 (90%)]\tLoss: 0.001278\n",
      "\n",
      "Validation set: Average loss: 0.0012, Accuracy: 3794/3870 (98%)\n",
      "\n",
      "Train Epoch: 73 [0/35339 (0%)]\tLoss: 0.000040\n",
      "Train Epoch: 73 [6400/35339 (18%)]\tLoss: 0.000117\n",
      "Train Epoch: 73 [12800/35339 (36%)]\tLoss: 0.000066\n",
      "Train Epoch: 73 [19200/35339 (54%)]\tLoss: 0.000055\n",
      "Train Epoch: 73 [25600/35339 (72%)]\tLoss: 0.000122\n",
      "Train Epoch: 73 [32000/35339 (90%)]\tLoss: 0.000014\n",
      "\n",
      "Validation set: Average loss: 0.0012, Accuracy: 3807/3870 (98%)\n",
      "\n",
      "Train Epoch: 74 [0/35339 (0%)]\tLoss: 0.000136\n",
      "Train Epoch: 74 [6400/35339 (18%)]\tLoss: 0.000031\n",
      "Train Epoch: 74 [12800/35339 (36%)]\tLoss: 0.000111\n",
      "Train Epoch: 74 [19200/35339 (54%)]\tLoss: 0.000102\n",
      "Train Epoch: 74 [25600/35339 (72%)]\tLoss: 0.000006\n",
      "Train Epoch: 74 [32000/35339 (90%)]\tLoss: 0.000016\n",
      "\n",
      "Validation set: Average loss: 0.0012, Accuracy: 3809/3870 (98%)\n",
      "\n",
      "Train Epoch: 75 [0/35339 (0%)]\tLoss: 0.000075\n",
      "Train Epoch: 75 [6400/35339 (18%)]\tLoss: 0.000022\n",
      "Train Epoch: 75 [12800/35339 (36%)]\tLoss: 0.000016\n",
      "Train Epoch: 75 [19200/35339 (54%)]\tLoss: 0.000012\n",
      "Train Epoch: 75 [25600/35339 (72%)]\tLoss: 0.000084\n",
      "Train Epoch: 75 [32000/35339 (90%)]\tLoss: 0.000023\n",
      "\n",
      "Validation set: Average loss: 0.0011, Accuracy: 3805/3870 (98%)\n",
      "\n",
      "Train Epoch: 76 [0/35339 (0%)]\tLoss: 0.000005\n",
      "Train Epoch: 76 [6400/35339 (18%)]\tLoss: 0.000012\n",
      "Train Epoch: 76 [12800/35339 (36%)]\tLoss: 0.000048\n",
      "Train Epoch: 76 [19200/35339 (54%)]\tLoss: 0.000017\n",
      "Train Epoch: 76 [25600/35339 (72%)]\tLoss: 0.000016\n",
      "Train Epoch: 76 [32000/35339 (90%)]\tLoss: 0.000010\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3815/3870 (99%)\n",
      "\n",
      "Train Epoch: 77 [0/35339 (0%)]\tLoss: 0.000015\n",
      "Train Epoch: 77 [6400/35339 (18%)]\tLoss: 0.000072\n",
      "Train Epoch: 77 [12800/35339 (36%)]\tLoss: 0.000028\n",
      "Train Epoch: 77 [19200/35339 (54%)]\tLoss: 0.087792\n",
      "Train Epoch: 77 [25600/35339 (72%)]\tLoss: 0.000287\n",
      "Train Epoch: 77 [32000/35339 (90%)]\tLoss: 0.000279\n",
      "\n",
      "Validation set: Average loss: 0.0032, Accuracy: 3679/3870 (95%)\n",
      "\n",
      "Train Epoch: 78 [0/35339 (0%)]\tLoss: 0.000768\n",
      "Train Epoch: 78 [6400/35339 (18%)]\tLoss: 0.000371\n",
      "Train Epoch: 78 [12800/35339 (36%)]\tLoss: 0.000110\n",
      "Train Epoch: 78 [19200/35339 (54%)]\tLoss: 0.000021\n",
      "Train Epoch: 78 [25600/35339 (72%)]\tLoss: 0.000052\n",
      "Train Epoch: 78 [32000/35339 (90%)]\tLoss: 0.000050\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3798/3870 (98%)\n",
      "\n",
      "Train Epoch: 79 [0/35339 (0%)]\tLoss: 0.000016\n",
      "Train Epoch: 79 [6400/35339 (18%)]\tLoss: 0.000025\n",
      "Train Epoch: 79 [12800/35339 (36%)]\tLoss: 0.000018\n",
      "Train Epoch: 79 [19200/35339 (54%)]\tLoss: 0.000058\n",
      "Train Epoch: 79 [25600/35339 (72%)]\tLoss: 0.000024\n",
      "Train Epoch: 79 [32000/35339 (90%)]\tLoss: 0.000019\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3796/3870 (98%)\n",
      "\n",
      "Train Epoch: 80 [0/35339 (0%)]\tLoss: 0.000007\n",
      "Train Epoch: 80 [6400/35339 (18%)]\tLoss: 0.000046\n",
      "Train Epoch: 80 [12800/35339 (36%)]\tLoss: 0.000025\n",
      "Train Epoch: 80 [19200/35339 (54%)]\tLoss: 0.000026\n",
      "Train Epoch: 80 [25600/35339 (72%)]\tLoss: 0.000015\n",
      "Train Epoch: 80 [32000/35339 (90%)]\tLoss: 0.000016\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3797/3870 (98%)\n",
      "\n",
      "Train Epoch: 81 [0/35339 (0%)]\tLoss: 0.000011\n",
      "Train Epoch: 81 [6400/35339 (18%)]\tLoss: 0.000006\n",
      "Train Epoch: 81 [12800/35339 (36%)]\tLoss: 0.000013\n",
      "Train Epoch: 81 [19200/35339 (54%)]\tLoss: 0.000007\n",
      "Train Epoch: 81 [25600/35339 (72%)]\tLoss: 0.000008\n",
      "Train Epoch: 81 [32000/35339 (90%)]\tLoss: 0.000004\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3804/3870 (98%)\n",
      "\n",
      "Train Epoch: 82 [0/35339 (0%)]\tLoss: 0.000032\n",
      "Train Epoch: 82 [6400/35339 (18%)]\tLoss: 0.000004\n",
      "Train Epoch: 82 [12800/35339 (36%)]\tLoss: 0.000005\n",
      "Train Epoch: 82 [19200/35339 (54%)]\tLoss: 0.000033\n",
      "Train Epoch: 82 [25600/35339 (72%)]\tLoss: 0.000043\n",
      "Train Epoch: 82 [32000/35339 (90%)]\tLoss: 0.000007\n",
      "\n",
      "Validation set: Average loss: 0.0007, Accuracy: 3812/3870 (99%)\n",
      "\n",
      "Train Epoch: 83 [0/35339 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 83 [6400/35339 (18%)]\tLoss: 0.000004\n",
      "Train Epoch: 83 [12800/35339 (36%)]\tLoss: 0.000026\n",
      "Train Epoch: 83 [19200/35339 (54%)]\tLoss: 0.000002\n",
      "Train Epoch: 83 [25600/35339 (72%)]\tLoss: 0.000007\n",
      "Train Epoch: 83 [32000/35339 (90%)]\tLoss: 0.000002\n",
      "\n",
      "Validation set: Average loss: 0.0007, Accuracy: 3815/3870 (99%)\n",
      "\n",
      "Train Epoch: 84 [0/35339 (0%)]\tLoss: 0.000007\n",
      "Train Epoch: 84 [6400/35339 (18%)]\tLoss: 0.000015\n",
      "Train Epoch: 84 [12800/35339 (36%)]\tLoss: 0.000005\n",
      "Train Epoch: 84 [19200/35339 (54%)]\tLoss: 0.000013\n",
      "Train Epoch: 84 [25600/35339 (72%)]\tLoss: 0.000002\n",
      "Train Epoch: 84 [32000/35339 (90%)]\tLoss: 0.000002\n",
      "\n",
      "Validation set: Average loss: 0.0006, Accuracy: 3813/3870 (99%)\n",
      "\n",
      "Train Epoch: 85 [0/35339 (0%)]\tLoss: 0.000006\n",
      "Train Epoch: 85 [6400/35339 (18%)]\tLoss: 0.000008\n",
      "Train Epoch: 85 [12800/35339 (36%)]\tLoss: 0.000001\n",
      "Train Epoch: 85 [19200/35339 (54%)]\tLoss: 0.000005\n",
      "Train Epoch: 85 [25600/35339 (72%)]\tLoss: 0.000006\n",
      "Train Epoch: 85 [32000/35339 (90%)]\tLoss: 0.000004\n",
      "\n",
      "Validation set: Average loss: 0.0006, Accuracy: 3825/3870 (99%)\n",
      "\n",
      "Train Epoch: 86 [0/35339 (0%)]\tLoss: 0.000003\n",
      "Train Epoch: 86 [6400/35339 (18%)]\tLoss: 0.000002\n",
      "Train Epoch: 86 [12800/35339 (36%)]\tLoss: 0.000006\n",
      "Train Epoch: 86 [19200/35339 (54%)]\tLoss: 0.000002\n",
      "Train Epoch: 86 [25600/35339 (72%)]\tLoss: 0.000001\n",
      "Train Epoch: 86 [32000/35339 (90%)]\tLoss: 0.000002\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3806/3870 (98%)\n",
      "\n",
      "Train Epoch: 87 [0/35339 (0%)]\tLoss: 0.000005\n",
      "Train Epoch: 87 [6400/35339 (18%)]\tLoss: 0.000351\n",
      "Train Epoch: 87 [12800/35339 (36%)]\tLoss: 0.000864\n",
      "Train Epoch: 87 [19200/35339 (54%)]\tLoss: 0.000509\n",
      "Train Epoch: 87 [25600/35339 (72%)]\tLoss: 0.000023\n",
      "Train Epoch: 87 [32000/35339 (90%)]\tLoss: 0.000511\n",
      "\n",
      "Validation set: Average loss: 0.0012, Accuracy: 3783/3870 (98%)\n",
      "\n",
      "Train Epoch: 88 [0/35339 (0%)]\tLoss: 0.017491\n",
      "Train Epoch: 88 [6400/35339 (18%)]\tLoss: 0.001660\n",
      "Train Epoch: 88 [12800/35339 (36%)]\tLoss: 0.000122\n",
      "Train Epoch: 88 [19200/35339 (54%)]\tLoss: 0.000056\n",
      "Train Epoch: 88 [25600/35339 (72%)]\tLoss: 0.000038\n",
      "Train Epoch: 88 [32000/35339 (90%)]\tLoss: 0.000011\n",
      "\n",
      "Validation set: Average loss: 0.0011, Accuracy: 3791/3870 (98%)\n",
      "\n",
      "Train Epoch: 89 [0/35339 (0%)]\tLoss: 0.000102\n",
      "Train Epoch: 89 [6400/35339 (18%)]\tLoss: 0.000076\n",
      "Train Epoch: 89 [12800/35339 (36%)]\tLoss: 0.000009\n",
      "Train Epoch: 89 [19200/35339 (54%)]\tLoss: 0.000028\n",
      "Train Epoch: 89 [25600/35339 (72%)]\tLoss: 0.000044\n",
      "Train Epoch: 89 [32000/35339 (90%)]\tLoss: 0.000006\n",
      "\n",
      "Validation set: Average loss: 0.0006, Accuracy: 3813/3870 (99%)\n",
      "\n",
      "Train Epoch: 90 [0/35339 (0%)]\tLoss: 0.000098\n",
      "Train Epoch: 90 [6400/35339 (18%)]\tLoss: 0.000003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 90 [12800/35339 (36%)]\tLoss: 0.000006\n",
      "Train Epoch: 90 [19200/35339 (54%)]\tLoss: 0.000035\n",
      "Train Epoch: 90 [25600/35339 (72%)]\tLoss: 0.000021\n",
      "Train Epoch: 90 [32000/35339 (90%)]\tLoss: 0.000013\n",
      "\n",
      "Validation set: Average loss: 0.0007, Accuracy: 3821/3870 (99%)\n",
      "\n",
      "Train Epoch: 91 [0/35339 (0%)]\tLoss: 0.000225\n",
      "Train Epoch: 91 [6400/35339 (18%)]\tLoss: 0.000014\n",
      "Train Epoch: 91 [12800/35339 (36%)]\tLoss: 0.000003\n",
      "Train Epoch: 91 [19200/35339 (54%)]\tLoss: 0.000005\n",
      "Train Epoch: 91 [25600/35339 (72%)]\tLoss: 0.000009\n",
      "Train Epoch: 91 [32000/35339 (90%)]\tLoss: 0.000003\n",
      "\n",
      "Validation set: Average loss: 0.0006, Accuracy: 3816/3870 (99%)\n",
      "\n",
      "Train Epoch: 92 [0/35339 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 92 [6400/35339 (18%)]\tLoss: 0.000002\n",
      "Train Epoch: 92 [12800/35339 (36%)]\tLoss: 0.000015\n",
      "Train Epoch: 92 [19200/35339 (54%)]\tLoss: 0.000006\n",
      "Train Epoch: 92 [25600/35339 (72%)]\tLoss: 0.000005\n",
      "Train Epoch: 92 [32000/35339 (90%)]\tLoss: 0.000017\n",
      "\n",
      "Validation set: Average loss: 0.0007, Accuracy: 3826/3870 (99%)\n",
      "\n",
      "Train Epoch: 93 [0/35339 (0%)]\tLoss: 0.000003\n",
      "Train Epoch: 93 [6400/35339 (18%)]\tLoss: 0.000002\n",
      "Train Epoch: 93 [12800/35339 (36%)]\tLoss: 0.000003\n",
      "Train Epoch: 93 [19200/35339 (54%)]\tLoss: 0.000006\n",
      "Train Epoch: 93 [25600/35339 (72%)]\tLoss: 0.000006\n",
      "Train Epoch: 93 [32000/35339 (90%)]\tLoss: 0.000020\n",
      "\n",
      "Validation set: Average loss: 0.0006, Accuracy: 3825/3870 (99%)\n",
      "\n",
      "Train Epoch: 94 [0/35339 (0%)]\tLoss: 0.000005\n",
      "Train Epoch: 94 [6400/35339 (18%)]\tLoss: 0.000004\n",
      "Train Epoch: 94 [12800/35339 (36%)]\tLoss: 0.000004\n",
      "Train Epoch: 94 [19200/35339 (54%)]\tLoss: 0.000011\n",
      "Train Epoch: 94 [25600/35339 (72%)]\tLoss: 0.000005\n",
      "Train Epoch: 94 [32000/35339 (90%)]\tLoss: 0.000002\n",
      "\n",
      "Validation set: Average loss: 0.0012, Accuracy: 3786/3870 (98%)\n",
      "\n",
      "Train Epoch: 95 [0/35339 (0%)]\tLoss: 0.000002\n",
      "Train Epoch: 95 [6400/35339 (18%)]\tLoss: 0.000078\n",
      "Train Epoch: 95 [12800/35339 (36%)]\tLoss: 0.000073\n",
      "Train Epoch: 95 [19200/35339 (54%)]\tLoss: 0.000121\n",
      "Train Epoch: 95 [25600/35339 (72%)]\tLoss: 0.000020\n",
      "Train Epoch: 95 [32000/35339 (90%)]\tLoss: 0.000046\n",
      "\n",
      "Validation set: Average loss: 0.0010, Accuracy: 3801/3870 (98%)\n",
      "\n",
      "Train Epoch: 96 [0/35339 (0%)]\tLoss: 0.000047\n",
      "Train Epoch: 96 [6400/35339 (18%)]\tLoss: 0.000102\n",
      "Train Epoch: 96 [12800/35339 (36%)]\tLoss: 0.000021\n",
      "Train Epoch: 96 [19200/35339 (54%)]\tLoss: 0.000027\n",
      "Train Epoch: 96 [25600/35339 (72%)]\tLoss: 0.000020\n",
      "Train Epoch: 96 [32000/35339 (90%)]\tLoss: 0.000017\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3799/3870 (98%)\n",
      "\n",
      "Train Epoch: 97 [0/35339 (0%)]\tLoss: 0.000016\n",
      "Train Epoch: 97 [6400/35339 (18%)]\tLoss: 0.000024\n",
      "Train Epoch: 97 [12800/35339 (36%)]\tLoss: 0.000007\n",
      "Train Epoch: 97 [19200/35339 (54%)]\tLoss: 0.000007\n",
      "Train Epoch: 97 [25600/35339 (72%)]\tLoss: 0.000034\n",
      "Train Epoch: 97 [32000/35339 (90%)]\tLoss: 0.000008\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3803/3870 (98%)\n",
      "\n",
      "Train Epoch: 98 [0/35339 (0%)]\tLoss: 0.000020\n",
      "Train Epoch: 98 [6400/35339 (18%)]\tLoss: 0.000017\n",
      "Train Epoch: 98 [12800/35339 (36%)]\tLoss: 0.000078\n",
      "Train Epoch: 98 [19200/35339 (54%)]\tLoss: 0.000014\n",
      "Train Epoch: 98 [25600/35339 (72%)]\tLoss: 0.000010\n",
      "Train Epoch: 98 [32000/35339 (90%)]\tLoss: 0.000011\n",
      "\n",
      "Validation set: Average loss: 0.0009, Accuracy: 3801/3870 (98%)\n",
      "\n",
      "Train Epoch: 99 [0/35339 (0%)]\tLoss: 0.000025\n",
      "Train Epoch: 99 [6400/35339 (18%)]\tLoss: 0.000006\n",
      "Train Epoch: 99 [12800/35339 (36%)]\tLoss: 0.000039\n",
      "Train Epoch: 99 [19200/35339 (54%)]\tLoss: 0.000009\n",
      "Train Epoch: 99 [25600/35339 (72%)]\tLoss: 0.000007\n",
      "Train Epoch: 99 [32000/35339 (90%)]\tLoss: 0.000015\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3809/3870 (98%)\n",
      "\n",
      "Train Epoch: 100 [0/35339 (0%)]\tLoss: 0.000004\n",
      "Train Epoch: 100 [6400/35339 (18%)]\tLoss: 0.000003\n",
      "Train Epoch: 100 [12800/35339 (36%)]\tLoss: 0.000065\n",
      "Train Epoch: 100 [19200/35339 (54%)]\tLoss: 0.000002\n",
      "Train Epoch: 100 [25600/35339 (72%)]\tLoss: 0.000011\n",
      "Train Epoch: 100 [32000/35339 (90%)]\tLoss: 0.000002\n",
      "\n",
      "Validation set: Average loss: 0.0008, Accuracy: 3800/3870 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_loss_log = []\n",
    "training_accuracy_log = []\n",
    "validation_loss_log = []\n",
    "validation_accuracy_log = []\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train_loss, training_accuracy = train(epoch)\n",
    "    validation_loss, validation_accuracy = validation() \n",
    "    \n",
    "    train_loss_log.append(train_loss)\n",
    "    training_accuracy_log.append(training_accuracy)\n",
    "    validation_loss_log.append(validation_loss)\n",
    "    validation_accuracy_log.append(validation_accuracy)\n",
    "    torch.save(model.state_dict(), \"model_GoogLeNet_2.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7924712896347046,\n",
       " 0.3036676049232483,\n",
       " 0.15681327879428864,\n",
       " 0.5670299530029297,\n",
       " 0.17080987989902496,\n",
       " 0.106110118329525,\n",
       " 0.003289439482614398,\n",
       " 0.014851570129394531,\n",
       " 0.00991006288677454,\n",
       " 0.006531022023409605,\n",
       " 0.03746071830391884,\n",
       " 0.6588125824928284,\n",
       " 0.005743720103055239,\n",
       " 0.0031580491922795773,\n",
       " 0.1905088871717453,\n",
       " 0.37279650568962097,\n",
       " 0.007019866723567247,\n",
       " 0.0038097987417131662,\n",
       " 0.030968492850661278,\n",
       " 0.0012933991383761168,\n",
       " 0.01674014888703823,\n",
       " 0.14856475591659546,\n",
       " 0.11762472987174988,\n",
       " 0.0012252114247530699,\n",
       " 0.009681441821157932,\n",
       " 0.004074010066688061,\n",
       " 0.0009423168958164752,\n",
       " 0.0027260780334472656,\n",
       " 0.0019452788401395082,\n",
       " 0.005451679229736328,\n",
       " 0.003414934268221259,\n",
       " 9.146603406406939e-05,\n",
       " 0.0027386925648897886,\n",
       " 0.0191967710852623,\n",
       " 0.0021269971039146185,\n",
       " 0.0030279159545898438,\n",
       " 0.007820823229849339,\n",
       " 0.0008407505811192095,\n",
       " 0.0008456490468233824,\n",
       " 0.0003374706720933318,\n",
       " 0.057292450219392776,\n",
       " 0.038414619863033295,\n",
       " 5.288557440508157e-05,\n",
       " 0.0021356234792619944,\n",
       " 0.0005707307136617601,\n",
       " 8.505040750605986e-05,\n",
       " 0.059522245079278946,\n",
       " 0.0085519440472126,\n",
       " 9.306994616053998e-05,\n",
       " 3.684650801005773e-05,\n",
       " 5.834753028466366e-05,\n",
       " 0.0003584948426578194,\n",
       " 0.08731365948915482,\n",
       " 0.0041092741303145885,\n",
       " 0.00015518882719334215,\n",
       " 0.00013087013212498277,\n",
       " 0.005266493186354637,\n",
       " 0.0005417736829258502,\n",
       " 0.0007551800226792693,\n",
       " 0.00036022879066877067,\n",
       " 0.0023268351797014475,\n",
       " 8.175589755410329e-05,\n",
       " 0.0024546494241803885,\n",
       " 0.00043071398977190256,\n",
       " 5.323236473486759e-05,\n",
       " 0.0013976964401081204,\n",
       " 8.713115676073357e-06,\n",
       " 0.0003450567019172013,\n",
       " 2.8740276320604607e-05,\n",
       " 6.30725480732508e-05,\n",
       " 0.0022123726084828377,\n",
       " 0.0023254482075572014,\n",
       " 0.0001506371918367222,\n",
       " 0.00021990863024257123,\n",
       " 0.00013585523993242532,\n",
       " 0.006776961497962475,\n",
       " 0.0012409903574734926,\n",
       " 0.00026819921913556755,\n",
       " 0.0006518147420138121,\n",
       " 0.005405263509601355,\n",
       " 0.0012153387069702148,\n",
       " 0.0003551569825503975,\n",
       " 2.7743253667722456e-05,\n",
       " 0.0003064112097490579,\n",
       " 2.8003345505567268e-05,\n",
       " 3.0214136131689884e-05,\n",
       " 0.0004936564946547151,\n",
       " 0.0008000893867574632,\n",
       " 0.0019294050289317966,\n",
       " 0.00010338696301914752,\n",
       " 0.002178983297199011,\n",
       " 0.00015872175572440028,\n",
       " 6.146864325273782e-05,\n",
       " 0.06937124580144882,\n",
       " 0.0006193247972987592,\n",
       " 3.155794911435805e-05,\n",
       " 8.127906039590016e-05,\n",
       " 0.00035745446803048253,\n",
       " 0.00018436257960274816,\n",
       " 1.0056929568236228e-05]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332,\n",
       " 90.41591320072332]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wrong training_accuracy_log\n",
    "training_accuracy_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03254980382434928,\n",
       " 0.01573230876979594,\n",
       " 0.010930789212963378,\n",
       " 0.01038276885060993,\n",
       " 0.00889364910391412,\n",
       " 0.006721790338979519,\n",
       " 0.0078048297557835435,\n",
       " 0.014788404368923,\n",
       " 0.006291105078884644,\n",
       " 0.008057985230510241,\n",
       " 0.006382588305431165,\n",
       " 0.005101729992528035,\n",
       " 0.003469952760482067,\n",
       " 0.004693130377958468,\n",
       " 0.0050291667064261995,\n",
       " 0.0035693345576385156,\n",
       " 0.0040146712764847345,\n",
       " 0.003671506004127041,\n",
       " 0.003041247164898098,\n",
       " 0.002669155363291887,\n",
       " 0.002266619340562501,\n",
       " 0.002218251418640737,\n",
       " 0.0017991341873164137,\n",
       " 0.002096348637963906,\n",
       " 0.0019732333123555425,\n",
       " 0.0020691887222221822,\n",
       " 0.001841602267779322,\n",
       " 0.0017860149927790311,\n",
       " 0.0016392674512703343,\n",
       " 0.0018700475800296325,\n",
       " 0.0008450486468637329,\n",
       " 0.0006875159058150056,\n",
       " 0.0008936468237155965,\n",
       " 0.0013036450815228728,\n",
       " 0.0018821849314934378,\n",
       " 0.0018698370642798385,\n",
       " 0.007247675898501732,\n",
       " 0.0010191499066126578,\n",
       " 0.0010546058978533007,\n",
       " 0.0013498489282106013,\n",
       " 0.0012682154323523558,\n",
       " 0.0006377523128683545,\n",
       " 0.0010038955307507572,\n",
       " 0.00086526216831588,\n",
       " 0.0006670790718200303,\n",
       " 0.0007274493299789499,\n",
       " 0.0007949861475329574,\n",
       " 0.0017636837587253857,\n",
       " 0.0009670480707312331,\n",
       " 0.0008067836710648943,\n",
       " 0.0008598033162627563,\n",
       " 0.0007724274362820298,\n",
       " 0.0010184355536407342,\n",
       " 0.0006403346675457445,\n",
       " 0.00044658998824809875,\n",
       " 0.000358747986532861,\n",
       " 0.0003176681300774879,\n",
       " 0.00029904174596769023,\n",
       " 0.0003216950957640486,\n",
       " 0.00033607926729881294,\n",
       " 0.0002466189749313193,\n",
       " 0.000284284134872682,\n",
       " 0.00026741288432286035,\n",
       " 0.0011359689187845437,\n",
       " 0.0010668512757123236,\n",
       " 0.0008350896290010224,\n",
       " 0.0007684945131104212,\n",
       " 0.0006827919045262673,\n",
       " 0.0006353557510518057,\n",
       " 0.0006698005528628035,\n",
       " 0.001901162644794532,\n",
       " 0.0012121940663438928,\n",
       " 0.0012123449096531577,\n",
       " 0.0011589582458228348,\n",
       " 0.001133090482108636,\n",
       " 0.0008927699075137442,\n",
       " 0.0032465239744207783,\n",
       " 0.0009427502754077711,\n",
       " 0.000882567246191839,\n",
       " 0.0009203937992013936,\n",
       " 0.0007722116127918358,\n",
       " 0.0006832862309116862,\n",
       " 0.0006905208617965415,\n",
       " 0.0006191847950996624,\n",
       " 0.0005666916795286713,\n",
       " 0.0007941582864735971,\n",
       " 0.0012032881469935966,\n",
       " 0.001119322429341336,\n",
       " 0.0006338874970038947,\n",
       " 0.0006695259711805469,\n",
       " 0.000621921937129781,\n",
       " 0.0006711085476173757,\n",
       " 0.0006320514763215322,\n",
       " 0.0011547946847468283,\n",
       " 0.0010325633660023797,\n",
       " 0.0009372364514259482,\n",
       " 0.0009016748036770004,\n",
       " 0.0008983469223098473,\n",
       " 0.0008074967267953834,\n",
       " 0.0008461314964876084]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43.30749354005168,\n",
       " 70.10335917312662,\n",
       " 81.52454780361757,\n",
       " 81.96382428940568,\n",
       " 85.01291989664082,\n",
       " 87.57105943152455,\n",
       " 86.66666666666667,\n",
       " 81.98966408268734,\n",
       " 89.50904392764858,\n",
       " 87.67441860465117,\n",
       " 89.17312661498708,\n",
       " 92.19638242894057,\n",
       " 93.87596899224806,\n",
       " 91.65374677002583,\n",
       " 92.09302325581395,\n",
       " 93.69509043927648,\n",
       " 93.69509043927648,\n",
       " 94.67700258397933,\n",
       " 94.70284237726098,\n",
       " 95.32299741602067,\n",
       " 96.07235142118863,\n",
       " 96.2015503875969,\n",
       " 96.69250645994832,\n",
       " 96.02067183462532,\n",
       " 96.40826873385014,\n",
       " 96.27906976744185,\n",
       " 96.5891472868217,\n",
       " 96.4857881136951,\n",
       " 96.82170542635659,\n",
       " 96.4857881136951,\n",
       " 98.03617571059432,\n",
       " 98.78552971576228,\n",
       " 98.11369509043928,\n",
       " 97.82945736434108,\n",
       " 96.77002583979328,\n",
       " 96.38242894056847,\n",
       " 90.62015503875969,\n",
       " 97.77777777777777,\n",
       " 97.59689922480621,\n",
       " 97.41602067183463,\n",
       " 97.57105943152455,\n",
       " 98.75968992248062,\n",
       " 97.95865633074935,\n",
       " 98.29457364341086,\n",
       " 98.50129198966408,\n",
       " 98.52713178294573,\n",
       " 98.50129198966408,\n",
       " 96.74418604651163,\n",
       " 98.11369509043928,\n",
       " 98.44961240310077,\n",
       " 98.39793281653746,\n",
       " 98.39793281653746,\n",
       " 97.95865633074935,\n",
       " 98.55297157622739,\n",
       " 99.12144702842377,\n",
       " 99.35400516795866,\n",
       " 99.30232558139535,\n",
       " 99.43152454780362,\n",
       " 99.35400516795866,\n",
       " 99.2248062015504,\n",
       " 99.45736434108527,\n",
       " 99.35400516795866,\n",
       " 99.40568475452196,\n",
       " 97.85529715762274,\n",
       " 97.98449612403101,\n",
       " 98.47545219638243,\n",
       " 98.55297157622739,\n",
       " 98.70801033591731,\n",
       " 98.81136950904393,\n",
       " 98.78552971576228,\n",
       " 96.43410852713178,\n",
       " 98.03617571059432,\n",
       " 98.37209302325581,\n",
       " 98.42377260981912,\n",
       " 98.3204134366925,\n",
       " 98.57881136950904,\n",
       " 95.06459948320413,\n",
       " 98.13953488372093,\n",
       " 98.08785529715762,\n",
       " 98.11369509043928,\n",
       " 98.29457364341086,\n",
       " 98.50129198966408,\n",
       " 98.57881136950904,\n",
       " 98.52713178294573,\n",
       " 98.83720930232558,\n",
       " 98.34625322997417,\n",
       " 97.75193798449612,\n",
       " 97.95865633074935,\n",
       " 98.52713178294573,\n",
       " 98.73385012919897,\n",
       " 98.6046511627907,\n",
       " 98.86304909560724,\n",
       " 98.83720930232558,\n",
       " 97.82945736434108,\n",
       " 98.21705426356588,\n",
       " 98.16537467700259,\n",
       " 98.2687338501292,\n",
       " 98.21705426356588,\n",
       " 98.42377260981912,\n",
       " 98.19121447028424]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "time = list(range(100))\n",
    "%matplotlib inline\n",
    "plt.plot(time,train_loss_log)\n",
    "plt.plot(time,validation_loss_log)\n",
    "plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "plt.ylabel(u'Cross Entrophy Loss',fontproperties='SimHei')\n",
    "plt.xlabel(u'Time',fontproperties='SimHei')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "time = list(range(100))\n",
    "\n",
    "plt.plot(time,validation_accuracy_log)\n",
    "plt.legend(['Validation Accuracy'], loc='lower right')\n",
    "plt.ylabel(u'Accuracy',fontproperties='SimHei')\n",
    "plt.xlabel(u'Time',fontproperties='SimHei')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
