{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "\n",
    "import torch\n",
    "\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "GeForce GTX 1070\n",
      "Memory Usage:\n",
      "Allocated: 0.0 MB\n",
      "Cached:    0.0 MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**2,1), 'MB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**2,1), 'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data(folder):\n",
    "    train_zip = folder + '/train_images.zip'\n",
    "    test_zip = folder + '/test_images.zip'\n",
    "    if not os.path.exists(train_zip) or not os.path.exists(test_zip):\n",
    "        raise(RuntimeError(\"Could not find \" + train_zip + \" and \" + test_zip\n",
    "              + ', please download them from https://www.kaggle.com/c/nyu-cv-fall-2018/data '))\n",
    "    # extract train_data.zip to train_data\n",
    "    train_folder = folder + '/train_images'\n",
    "    if not os.path.isdir(train_folder):\n",
    "        print(train_folder + ' not found, extracting ' + train_zip)\n",
    "        zip_ref = zipfile.ZipFile(train_zip, 'r')\n",
    "        zip_ref.extractall(folder)\n",
    "        zip_ref.close()\n",
    "    # extract test_data.zip to test_data\n",
    "    test_folder = folder + '/test_images'\n",
    "    if not os.path.isdir(test_folder):\n",
    "        print(test_folder + ' not found, extracting ' + test_zip)\n",
    "        zip_ref = zipfile.ZipFile(test_zip, 'r')\n",
    "        zip_ref.extractall(folder)\n",
    "        zip_ref.close()\n",
    "\n",
    "    # make validation_data by using images 00000*, 00001* and 00002* in each class\n",
    "    val_folder = folder + '/val_images'\n",
    "    if not os.path.isdir(val_folder):\n",
    "        print(val_folder + ' not found, making a validation set')\n",
    "        os.mkdir(val_folder)\n",
    "        for dirs in os.listdir(train_folder):\n",
    "            if dirs.startswith('000'):\n",
    "                os.mkdir(val_folder + '/' + dirs)\n",
    "                for f in os.listdir(train_folder + '/' + dirs):\n",
    "                    if f.startswith('00000') or f.startswith('00001') or f.startswith('00002'):\n",
    "                        # move file to validation folder\n",
    "                        os.rename(train_folder + '/' + dirs + '/' + f, val_folder + '/' + dirs + '/' + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'D:/Sync/Courses/Level_3/CV/Courant-CSCI-2271-Computer-Vision/Assignment_2'\n",
    "initialize_data(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = 'C:/Users/tiany/Assignment_2'\n",
    "initialize_data(address)\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.3337, 0.3064, 0.3171), (0.2672, 0.2564, 0.2629))\n",
    "])\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    'batch_size': 100,\n",
    "    'epochs':100,\n",
    "    'lr':0.0001,\n",
    "    'momentum':0.5,\n",
    "    'seed':1,\n",
    "    'log_interval':100,\n",
    "    'weight_decay':1e-2\n",
    "})\n",
    "\n",
    "kwargs = {'num_workers': 12, 'pin_memory': True}\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(address + '/train_images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(address + '/val_images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=args.batch_size, shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nclasses = 43\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(100, 150, kernel_size=4)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.conv3 = nn.Conv2d(150, 250, kernel_size=3)\n",
    "        self.conv3_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(1000, 200)\n",
    "        self.fc2 = nn.Linear(200, nclasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv3_drop(self.conv3(x)), 2))\n",
    "        x = x.view(-1, 250*4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Neural Network and Optimizer\n",
    "# We define neural net in model.py so that it can be reused by the evaluate.py script\n",
    "model = Net().to(device)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=args.lr,weight_decay=args.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 100, 30, 30]           2,800\n",
      "            Conv2d-2          [-1, 150, 12, 12]         240,150\n",
      "         Dropout2d-3          [-1, 150, 12, 12]               0\n",
      "            Conv2d-4            [-1, 250, 4, 4]         337,750\n",
      "         Dropout2d-5            [-1, 250, 4, 4]               0\n",
      "            Linear-6                  [-1, 200]         200,200\n",
      "            Linear-7                   [-1, 43]           8,643\n",
      "================================================================\n",
      "Total params: 789,543\n",
      "Trainable params: 789,543\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.08\n",
      "Params size (MB): 3.01\n",
      "Estimated Total Size (MB): 4.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "torchsummary.summary(model,input_size=(3,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        train_loss = F.cross_entropy(output,target).to(device)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        pred = output.argmax(dim=1, keepdim=True)# get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        training_accuracy = 100. * correct / len(train_loader.dataset)\n",
    "        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {}/{} ({:.6f}%)'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), train_loss.item(),\n",
    "                correct, len(train_loader.dataset), training_accuracy))\n",
    "\n",
    "    return train_loss.item(), training_accuracy\n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        validation_loss += F.cross_entropy(output,target).to(device).item() # sum up batch loss\n",
    "        pred = output.argmax(dim=1, keepdim=True)# get the index of the max log-probability\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    validation_accuracy = 100. * correct / len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.6f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset), validation_accuracy))\n",
    "    return validation_loss, validation_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tiany\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/35339 (0%)]\tLoss: 3.500224\tAccuracy: 5/35339 (0.014149%)\n",
      "Train Epoch: 1 [10000/35339 (28%)]\tLoss: 3.256943\tAccuracy: 996/35339 (2.818416%)\n",
      "Train Epoch: 1 [20000/35339 (56%)]\tLoss: 2.955888\tAccuracy: 2573/35339 (7.280908%)\n",
      "Train Epoch: 1 [30000/35339 (85%)]\tLoss: 2.710732\tAccuracy: 4853/35339 (13.732703%)\n",
      "\n",
      "Validation set: Average loss: 0.034477, Accuracy: 647/3870 (16.718346%)\n",
      "\n",
      "Train Epoch: 2 [0/35339 (0%)]\tLoss: 2.434618\tAccuracy: 32/35339 (0.090552%)\n",
      "Train Epoch: 2 [10000/35339 (28%)]\tLoss: 2.195299\tAccuracy: 3529/35339 (9.986134%)\n",
      "Train Epoch: 2 [20000/35339 (56%)]\tLoss: 1.737124\tAccuracy: 7717/35339 (21.837064%)\n",
      "Train Epoch: 2 [30000/35339 (85%)]\tLoss: 1.585825\tAccuracy: 12426/35339 (35.162285%)\n",
      "\n",
      "Validation set: Average loss: 0.024052, Accuracy: 1219/3870 (31.498708%)\n",
      "\n",
      "Train Epoch: 3 [0/35339 (0%)]\tLoss: 1.225501\tAccuracy: 66/35339 (0.186763%)\n",
      "Train Epoch: 3 [10000/35339 (28%)]\tLoss: 1.447375\tAccuracy: 5465/35339 (15.464501%)\n",
      "Train Epoch: 3 [20000/35339 (56%)]\tLoss: 1.277475\tAccuracy: 11292/35339 (31.953366%)\n",
      "Train Epoch: 3 [30000/35339 (85%)]\tLoss: 1.152809\tAccuracy: 17596/35339 (49.792014%)\n",
      "\n",
      "Validation set: Average loss: 0.015834, Accuracy: 2204/3870 (56.950904%)\n",
      "\n",
      "Train Epoch: 4 [0/35339 (0%)]\tLoss: 1.149604\tAccuracy: 67/35339 (0.189592%)\n",
      "Train Epoch: 4 [10000/35339 (28%)]\tLoss: 0.931573\tAccuracy: 7010/35339 (19.836441%)\n",
      "Train Epoch: 4 [20000/35339 (56%)]\tLoss: 0.905613\tAccuracy: 14226/35339 (40.255808%)\n",
      "Train Epoch: 4 [30000/35339 (85%)]\tLoss: 0.961677\tAccuracy: 21773/35339 (61.611817%)\n",
      "\n",
      "Validation set: Average loss: 0.010722, Accuracy: 2723/3870 (70.361757%)\n",
      "\n",
      "Train Epoch: 5 [0/35339 (0%)]\tLoss: 0.839009\tAccuracy: 73/35339 (0.206571%)\n",
      "Train Epoch: 5 [10000/35339 (28%)]\tLoss: 0.594276\tAccuracy: 7957/35339 (22.516200%)\n",
      "Train Epoch: 5 [20000/35339 (56%)]\tLoss: 0.628014\tAccuracy: 16005/35339 (45.289906%)\n",
      "Train Epoch: 5 [30000/35339 (85%)]\tLoss: 0.544411\tAccuracy: 24246/35339 (68.609751%)\n",
      "\n",
      "Validation set: Average loss: 0.008102, Accuracy: 2979/3870 (76.976744%)\n",
      "\n",
      "Train Epoch: 6 [0/35339 (0%)]\tLoss: 0.546322\tAccuracy: 87/35339 (0.246187%)\n",
      "Train Epoch: 6 [10000/35339 (28%)]\tLoss: 0.438817\tAccuracy: 8536/35339 (24.154617%)\n",
      "Train Epoch: 6 [20000/35339 (56%)]\tLoss: 0.451658\tAccuracy: 17114/35339 (48.428082%)\n",
      "Train Epoch: 6 [30000/35339 (85%)]\tLoss: 0.420411\tAccuracy: 25815/35339 (73.049605%)\n",
      "\n",
      "Validation set: Average loss: 0.006069, Accuracy: 3244/3870 (83.824289%)\n",
      "\n",
      "Train Epoch: 7 [0/35339 (0%)]\tLoss: 0.349407\tAccuracy: 88/35339 (0.249017%)\n",
      "Train Epoch: 7 [10000/35339 (28%)]\tLoss: 0.559994\tAccuracy: 8911/35339 (25.215767%)\n",
      "Train Epoch: 7 [20000/35339 (56%)]\tLoss: 0.423085\tAccuracy: 17791/35339 (50.343813%)\n",
      "Train Epoch: 7 [30000/35339 (85%)]\tLoss: 0.278243\tAccuracy: 26768/35339 (75.746343%)\n",
      "\n",
      "Validation set: Average loss: 0.004970, Accuracy: 3363/3870 (86.899225%)\n",
      "\n",
      "Train Epoch: 8 [0/35339 (0%)]\tLoss: 0.394057\tAccuracy: 86/35339 (0.243357%)\n",
      "Train Epoch: 8 [10000/35339 (28%)]\tLoss: 0.444615\tAccuracy: 9107/35339 (25.770395%)\n",
      "Train Epoch: 8 [20000/35339 (56%)]\tLoss: 0.278255\tAccuracy: 18218/35339 (51.552110%)\n",
      "Train Epoch: 8 [30000/35339 (85%)]\tLoss: 0.298590\tAccuracy: 27418/35339 (77.585670%)\n",
      "\n",
      "Validation set: Average loss: 0.004675, Accuracy: 3397/3870 (87.777778%)\n",
      "\n",
      "Train Epoch: 9 [0/35339 (0%)]\tLoss: 0.328146\tAccuracy: 92/35339 (0.260336%)\n",
      "Train Epoch: 9 [10000/35339 (28%)]\tLoss: 0.203899\tAccuracy: 9320/35339 (26.373129%)\n",
      "Train Epoch: 9 [20000/35339 (56%)]\tLoss: 0.254589\tAccuracy: 18549/35339 (52.488752%)\n",
      "Train Epoch: 9 [30000/35339 (85%)]\tLoss: 0.178327\tAccuracy: 27886/35339 (78.909986%)\n",
      "\n",
      "Validation set: Average loss: 0.003826, Accuracy: 3495/3870 (90.310078%)\n",
      "\n",
      "Train Epoch: 10 [0/35339 (0%)]\tLoss: 0.240199\tAccuracy: 92/35339 (0.260336%)\n",
      "Train Epoch: 10 [10000/35339 (28%)]\tLoss: 0.232065\tAccuracy: 9416/35339 (26.644783%)\n",
      "Train Epoch: 10 [20000/35339 (56%)]\tLoss: 0.274512\tAccuracy: 18798/35339 (53.193356%)\n",
      "Train Epoch: 10 [30000/35339 (85%)]\tLoss: 0.185301\tAccuracy: 28227/35339 (79.874926%)\n",
      "\n",
      "Validation set: Average loss: 0.003609, Accuracy: 3521/3870 (90.981912%)\n",
      "\n",
      "Train Epoch: 11 [0/35339 (0%)]\tLoss: 0.257496\tAccuracy: 91/35339 (0.257506%)\n",
      "Train Epoch: 11 [10000/35339 (28%)]\tLoss: 0.246584\tAccuracy: 9575/35339 (27.094711%)\n",
      "Train Epoch: 11 [20000/35339 (56%)]\tLoss: 0.112292\tAccuracy: 19034/35339 (53.861173%)\n",
      "Train Epoch: 11 [30000/35339 (85%)]\tLoss: 0.170082\tAccuracy: 28522/35339 (80.709698%)\n",
      "\n",
      "Validation set: Average loss: 0.003374, Accuracy: 3550/3870 (91.731266%)\n",
      "\n",
      "Train Epoch: 12 [0/35339 (0%)]\tLoss: 0.248843\tAccuracy: 94/35339 (0.265995%)\n",
      "Train Epoch: 12 [10000/35339 (28%)]\tLoss: 0.239800\tAccuracy: 9632/35339 (27.256006%)\n",
      "Train Epoch: 12 [20000/35339 (56%)]\tLoss: 0.246714\tAccuracy: 19159/35339 (54.214890%)\n",
      "Train Epoch: 12 [30000/35339 (85%)]\tLoss: 0.137927\tAccuracy: 28706/35339 (81.230369%)\n",
      "\n",
      "Validation set: Average loss: 0.003083, Accuracy: 3585/3870 (92.635659%)\n",
      "\n",
      "Train Epoch: 13 [0/35339 (0%)]\tLoss: 0.086975\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 13 [10000/35339 (28%)]\tLoss: 0.089768\tAccuracy: 9693/35339 (27.428620%)\n",
      "Train Epoch: 13 [20000/35339 (56%)]\tLoss: 0.136200\tAccuracy: 19292/35339 (54.591245%)\n",
      "Train Epoch: 13 [30000/35339 (85%)]\tLoss: 0.037310\tAccuracy: 28892/35339 (81.756699%)\n",
      "\n",
      "Validation set: Average loss: 0.003024, Accuracy: 3579/3870 (92.480620%)\n",
      "\n",
      "Train Epoch: 14 [0/35339 (0%)]\tLoss: 0.050014\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 14 [10000/35339 (28%)]\tLoss: 0.069246\tAccuracy: 9750/35339 (27.589915%)\n",
      "Train Epoch: 14 [20000/35339 (56%)]\tLoss: 0.047927\tAccuracy: 19355/35339 (54.769518%)\n",
      "Train Epoch: 14 [30000/35339 (85%)]\tLoss: 0.159957\tAccuracy: 28974/35339 (81.988738%)\n",
      "\n",
      "Validation set: Average loss: 0.002906, Accuracy: 3594/3870 (92.868217%)\n",
      "\n",
      "Train Epoch: 15 [0/35339 (0%)]\tLoss: 0.116472\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 15 [10000/35339 (28%)]\tLoss: 0.040673\tAccuracy: 9778/35339 (27.669147%)\n",
      "Train Epoch: 15 [20000/35339 (56%)]\tLoss: 0.129802\tAccuracy: 19419/35339 (54.950621%)\n",
      "Train Epoch: 15 [30000/35339 (85%)]\tLoss: 0.077614\tAccuracy: 29095/35339 (82.331136%)\n",
      "\n",
      "Validation set: Average loss: 0.002673, Accuracy: 3617/3870 (93.462532%)\n",
      "\n",
      "Train Epoch: 16 [0/35339 (0%)]\tLoss: 0.085231\tAccuracy: 96/35339 (0.271655%)\n",
      "Train Epoch: 16 [10000/35339 (28%)]\tLoss: 0.127778\tAccuracy: 9794/35339 (27.714423%)\n",
      "Train Epoch: 16 [20000/35339 (56%)]\tLoss: 0.090853\tAccuracy: 19521/35339 (55.239254%)\n",
      "Train Epoch: 16 [30000/35339 (85%)]\tLoss: 0.102343\tAccuracy: 29229/35339 (82.710320%)\n",
      "\n",
      "Validation set: Average loss: 0.002806, Accuracy: 3608/3870 (93.229974%)\n",
      "\n",
      "Train Epoch: 17 [0/35339 (0%)]\tLoss: 0.131038\tAccuracy: 97/35339 (0.274484%)\n",
      "Train Epoch: 17 [10000/35339 (28%)]\tLoss: 0.085096\tAccuracy: 9846/35339 (27.861569%)\n",
      "Train Epoch: 17 [20000/35339 (56%)]\tLoss: 0.083084\tAccuracy: 19576/35339 (55.394889%)\n",
      "Train Epoch: 17 [30000/35339 (85%)]\tLoss: 0.132912\tAccuracy: 29299/35339 (82.908401%)\n",
      "\n",
      "Validation set: Average loss: 0.002625, Accuracy: 3609/3870 (93.255814%)\n",
      "\n",
      "Train Epoch: 18 [0/35339 (0%)]\tLoss: 0.064784\tAccuracy: 97/35339 (0.274484%)\n",
      "Train Epoch: 18 [10000/35339 (28%)]\tLoss: 0.077385\tAccuracy: 9859/35339 (27.898356%)\n",
      "Train Epoch: 18 [20000/35339 (56%)]\tLoss: 0.086598\tAccuracy: 19607/35339 (55.482611%)\n",
      "Train Epoch: 18 [30000/35339 (85%)]\tLoss: 0.064717\tAccuracy: 29373/35339 (83.117802%)\n",
      "\n",
      "Validation set: Average loss: 0.002375, Accuracy: 3640/3870 (94.056848%)\n",
      "\n",
      "Train Epoch: 19 [0/35339 (0%)]\tLoss: 0.132689\tAccuracy: 96/35339 (0.271655%)\n",
      "Train Epoch: 19 [10000/35339 (28%)]\tLoss: 0.100230\tAccuracy: 9872/35339 (27.935142%)\n",
      "Train Epoch: 19 [20000/35339 (56%)]\tLoss: 0.100344\tAccuracy: 19652/35339 (55.609949%)\n",
      "Train Epoch: 19 [30000/35339 (85%)]\tLoss: 0.103185\tAccuracy: 29431/35339 (83.281926%)\n",
      "\n",
      "Validation set: Average loss: 0.002259, Accuracy: 3660/3870 (94.573643%)\n",
      "\n",
      "Train Epoch: 20 [0/35339 (0%)]\tLoss: 0.114192\tAccuracy: 96/35339 (0.271655%)\n",
      "Train Epoch: 20 [10000/35339 (28%)]\tLoss: 0.059075\tAccuracy: 9890/35339 (27.986078%)\n",
      "Train Epoch: 20 [20000/35339 (56%)]\tLoss: 0.088097\tAccuracy: 19693/35339 (55.725968%)\n",
      "Train Epoch: 20 [30000/35339 (85%)]\tLoss: 0.089835\tAccuracy: 29485/35339 (83.434732%)\n",
      "\n",
      "Validation set: Average loss: 0.002404, Accuracy: 3634/3870 (93.901809%)\n",
      "\n",
      "Train Epoch: 21 [0/35339 (0%)]\tLoss: 0.022216\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 21 [10000/35339 (28%)]\tLoss: 0.098324\tAccuracy: 9912/35339 (28.048332%)\n",
      "Train Epoch: 21 [20000/35339 (56%)]\tLoss: 0.049881\tAccuracy: 19733/35339 (55.839158%)\n",
      "Train Epoch: 21 [30000/35339 (85%)]\tLoss: 0.137752\tAccuracy: 29555/35339 (83.632814%)\n",
      "\n",
      "Validation set: Average loss: 0.002211, Accuracy: 3657/3870 (94.496124%)\n",
      "\n",
      "Train Epoch: 22 [0/35339 (0%)]\tLoss: 0.030378\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 22 [10000/35339 (28%)]\tLoss: 0.054270\tAccuracy: 9918/35339 (28.065310%)\n",
      "Train Epoch: 22 [20000/35339 (56%)]\tLoss: 0.081632\tAccuracy: 19755/35339 (55.901412%)\n",
      "Train Epoch: 22 [30000/35339 (85%)]\tLoss: 0.049626\tAccuracy: 29573/35339 (83.683749%)\n",
      "\n",
      "Validation set: Average loss: 0.002254, Accuracy: 3650/3870 (94.315245%)\n",
      "\n",
      "Train Epoch: 23 [0/35339 (0%)]\tLoss: 0.050735\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 23 [10000/35339 (28%)]\tLoss: 0.064723\tAccuracy: 9929/35339 (28.096437%)\n",
      "Train Epoch: 23 [20000/35339 (56%)]\tLoss: 0.031170\tAccuracy: 19785/35339 (55.986304%)\n",
      "Train Epoch: 23 [30000/35339 (85%)]\tLoss: 0.095009\tAccuracy: 29622/35339 (83.822406%)\n",
      "\n",
      "Validation set: Average loss: 0.002215, Accuracy: 3650/3870 (94.315245%)\n",
      "\n",
      "Train Epoch: 24 [0/35339 (0%)]\tLoss: 0.020526\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 24 [10000/35339 (28%)]\tLoss: 0.053817\tAccuracy: 9936/35339 (28.116246%)\n",
      "Train Epoch: 24 [20000/35339 (56%)]\tLoss: 0.078954\tAccuracy: 19779/35339 (55.969326%)\n",
      "Train Epoch: 24 [30000/35339 (85%)]\tLoss: 0.014685\tAccuracy: 29622/35339 (83.822406%)\n",
      "\n",
      "Validation set: Average loss: 0.002126, Accuracy: 3657/3870 (94.496124%)\n",
      "\n",
      "Train Epoch: 25 [0/35339 (0%)]\tLoss: 0.085954\tAccuracy: 97/35339 (0.274484%)\n",
      "Train Epoch: 25 [10000/35339 (28%)]\tLoss: 0.032826\tAccuracy: 9968/35339 (28.206797%)\n",
      "Train Epoch: 25 [20000/35339 (56%)]\tLoss: 0.067686\tAccuracy: 19833/35339 (56.122131%)\n",
      "Train Epoch: 25 [30000/35339 (85%)]\tLoss: 0.023325\tAccuracy: 29684/35339 (83.997849%)\n",
      "\n",
      "Validation set: Average loss: 0.002033, Accuracy: 3658/3870 (94.521964%)\n",
      "\n",
      "Train Epoch: 26 [0/35339 (0%)]\tLoss: 0.061356\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 26 [10000/35339 (28%)]\tLoss: 0.054596\tAccuracy: 9955/35339 (28.170010%)\n",
      "Train Epoch: 26 [20000/35339 (56%)]\tLoss: 0.048418\tAccuracy: 19818/35339 (56.079685%)\n",
      "Train Epoch: 26 [30000/35339 (85%)]\tLoss: 0.051671\tAccuracy: 29688/35339 (84.009168%)\n",
      "\n",
      "Validation set: Average loss: 0.001998, Accuracy: 3663/3870 (94.651163%)\n",
      "\n",
      "Train Epoch: 27 [0/35339 (0%)]\tLoss: 0.105636\tAccuracy: 95/35339 (0.268825%)\n",
      "Train Epoch: 27 [10000/35339 (28%)]\tLoss: 0.018394\tAccuracy: 9992/35339 (28.274711%)\n",
      "Train Epoch: 27 [20000/35339 (56%)]\tLoss: 0.095276\tAccuracy: 19877/35339 (56.246640%)\n",
      "Train Epoch: 27 [30000/35339 (85%)]\tLoss: 0.035358\tAccuracy: 29761/35339 (84.215739%)\n",
      "\n",
      "Validation set: Average loss: 0.002008, Accuracy: 3662/3870 (94.625323%)\n",
      "\n",
      "Train Epoch: 28 [0/35339 (0%)]\tLoss: 0.033417\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 28 [10000/35339 (28%)]\tLoss: 0.033427\tAccuracy: 9989/35339 (28.266221%)\n",
      "Train Epoch: 28 [20000/35339 (56%)]\tLoss: 0.039215\tAccuracy: 19859/35339 (56.195704%)\n",
      "Train Epoch: 28 [30000/35339 (85%)]\tLoss: 0.047542\tAccuracy: 29708/35339 (84.065763%)\n",
      "\n",
      "Validation set: Average loss: 0.002068, Accuracy: 3669/3870 (94.806202%)\n",
      "\n",
      "Train Epoch: 29 [0/35339 (0%)]\tLoss: 0.038516\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 29 [10000/35339 (28%)]\tLoss: 0.031528\tAccuracy: 9986/35339 (28.257732%)\n",
      "Train Epoch: 29 [20000/35339 (56%)]\tLoss: 0.031778\tAccuracy: 19876/35339 (56.243810%)\n",
      "Train Epoch: 29 [30000/35339 (85%)]\tLoss: 0.069056\tAccuracy: 29759/35339 (84.210080%)\n",
      "\n",
      "Validation set: Average loss: 0.002014, Accuracy: 3672/3870 (94.883721%)\n",
      "\n",
      "Train Epoch: 30 [0/35339 (0%)]\tLoss: 0.046145\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 30 [10000/35339 (28%)]\tLoss: 0.039883\tAccuracy: 9981/35339 (28.243584%)\n",
      "Train Epoch: 30 [20000/35339 (56%)]\tLoss: 0.019502\tAccuracy: 19893/35339 (56.291915%)\n",
      "Train Epoch: 30 [30000/35339 (85%)]\tLoss: 0.018128\tAccuracy: 29794/35339 (84.309120%)\n",
      "\n",
      "Validation set: Average loss: 0.001857, Accuracy: 3670/3870 (94.832041%)\n",
      "\n",
      "Train Epoch: 31 [0/35339 (0%)]\tLoss: 0.067160\tAccuracy: 97/35339 (0.274484%)\n",
      "Train Epoch: 31 [10000/35339 (28%)]\tLoss: 0.012552\tAccuracy: 10008/35339 (28.319986%)\n",
      "Train Epoch: 31 [20000/35339 (56%)]\tLoss: 0.010575\tAccuracy: 19894/35339 (56.294745%)\n",
      "Train Epoch: 31 [30000/35339 (85%)]\tLoss: 0.029072\tAccuracy: 29789/35339 (84.294972%)\n",
      "\n",
      "Validation set: Average loss: 0.001881, Accuracy: 3670/3870 (94.832041%)\n",
      "\n",
      "Train Epoch: 32 [0/35339 (0%)]\tLoss: 0.032413\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 32 [10000/35339 (28%)]\tLoss: 0.080831\tAccuracy: 9978/35339 (28.235094%)\n",
      "Train Epoch: 32 [20000/35339 (56%)]\tLoss: 0.006685\tAccuracy: 19875/35339 (56.240980%)\n",
      "Train Epoch: 32 [30000/35339 (85%)]\tLoss: 0.054129\tAccuracy: 29793/35339 (84.306291%)\n",
      "\n",
      "Validation set: Average loss: 0.001794, Accuracy: 3695/3870 (95.478036%)\n",
      "\n",
      "Train Epoch: 33 [0/35339 (0%)]\tLoss: 0.057177\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 33 [10000/35339 (28%)]\tLoss: 0.065660\tAccuracy: 9998/35339 (28.291689%)\n",
      "Train Epoch: 33 [20000/35339 (56%)]\tLoss: 0.027729\tAccuracy: 19914/35339 (56.351340%)\n",
      "Train Epoch: 33 [30000/35339 (85%)]\tLoss: 0.040023\tAccuracy: 29824/35339 (84.394012%)\n",
      "\n",
      "Validation set: Average loss: 0.001868, Accuracy: 3684/3870 (95.193798%)\n",
      "\n",
      "Train Epoch: 34 [0/35339 (0%)]\tLoss: 0.019718\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 34 [10000/35339 (28%)]\tLoss: 0.049507\tAccuracy: 10016/35339 (28.342624%)\n",
      "Train Epoch: 34 [20000/35339 (56%)]\tLoss: 0.040569\tAccuracy: 19926/35339 (56.385297%)\n",
      "Train Epoch: 34 [30000/35339 (85%)]\tLoss: 0.042599\tAccuracy: 29830/35339 (84.410991%)\n",
      "\n",
      "Validation set: Average loss: 0.002115, Accuracy: 3661/3870 (94.599483%)\n",
      "\n",
      "Train Epoch: 35 [0/35339 (0%)]\tLoss: 0.018301\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 35 [10000/35339 (28%)]\tLoss: 0.037220\tAccuracy: 10020/35339 (28.353943%)\n",
      "Train Epoch: 35 [20000/35339 (56%)]\tLoss: 0.035447\tAccuracy: 19936/35339 (56.413594%)\n",
      "Train Epoch: 35 [30000/35339 (85%)]\tLoss: 0.030815\tAccuracy: 29847/35339 (84.459096%)\n",
      "\n",
      "Validation set: Average loss: 0.001823, Accuracy: 3674/3870 (94.935401%)\n",
      "\n",
      "Train Epoch: 36 [0/35339 (0%)]\tLoss: 0.018153\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 36 [10000/35339 (28%)]\tLoss: 0.020453\tAccuracy: 10006/35339 (28.314327%)\n",
      "Train Epoch: 36 [20000/35339 (56%)]\tLoss: 0.023805\tAccuracy: 19944/35339 (56.436232%)\n",
      "Train Epoch: 36 [30000/35339 (85%)]\tLoss: 0.025267\tAccuracy: 29862/35339 (84.501542%)\n",
      "\n",
      "Validation set: Average loss: 0.001883, Accuracy: 3697/3870 (95.529716%)\n",
      "\n",
      "Train Epoch: 37 [0/35339 (0%)]\tLoss: 0.071554\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 37 [10000/35339 (28%)]\tLoss: 0.063851\tAccuracy: 10021/35339 (28.356773%)\n",
      "Train Epoch: 37 [20000/35339 (56%)]\tLoss: 0.020669\tAccuracy: 19942/35339 (56.430572%)\n",
      "Train Epoch: 37 [30000/35339 (85%)]\tLoss: 0.033254\tAccuracy: 29855/35339 (84.481734%)\n",
      "\n",
      "Validation set: Average loss: 0.001871, Accuracy: 3685/3870 (95.219638%)\n",
      "\n",
      "Train Epoch: 38 [0/35339 (0%)]\tLoss: 0.010625\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 38 [10000/35339 (28%)]\tLoss: 0.011689\tAccuracy: 10035/35339 (28.396389%)\n",
      "Train Epoch: 38 [20000/35339 (56%)]\tLoss: 0.042252\tAccuracy: 19950/35339 (56.453210%)\n",
      "Train Epoch: 38 [30000/35339 (85%)]\tLoss: 0.012936\tAccuracy: 29863/35339 (84.504372%)\n",
      "\n",
      "Validation set: Average loss: 0.001743, Accuracy: 3687/3870 (95.271318%)\n",
      "\n",
      "Train Epoch: 39 [0/35339 (0%)]\tLoss: 0.027065\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 39 [10000/35339 (28%)]\tLoss: 0.009918\tAccuracy: 10018/35339 (28.348284%)\n",
      "Train Epoch: 39 [20000/35339 (56%)]\tLoss: 0.078479\tAccuracy: 19933/35339 (56.405105%)\n",
      "Train Epoch: 39 [30000/35339 (85%)]\tLoss: 0.018220\tAccuracy: 29839/35339 (84.436458%)\n",
      "\n",
      "Validation set: Average loss: 0.001675, Accuracy: 3703/3870 (95.684755%)\n",
      "\n",
      "Train Epoch: 40 [0/35339 (0%)]\tLoss: 0.044907\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 40 [10000/35339 (28%)]\tLoss: 0.008348\tAccuracy: 10007/35339 (28.317157%)\n",
      "Train Epoch: 40 [20000/35339 (56%)]\tLoss: 0.079095\tAccuracy: 19930/35339 (56.396616%)\n",
      "Train Epoch: 40 [30000/35339 (85%)]\tLoss: 0.021012\tAccuracy: 29867/35339 (84.515691%)\n",
      "\n",
      "Validation set: Average loss: 0.001673, Accuracy: 3703/3870 (95.684755%)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 41 [0/35339 (0%)]\tLoss: 0.073884\tAccuracy: 97/35339 (0.274484%)\n",
      "Train Epoch: 41 [10000/35339 (28%)]\tLoss: 0.021440\tAccuracy: 10033/35339 (28.390730%)\n",
      "Train Epoch: 41 [20000/35339 (56%)]\tLoss: 0.031771\tAccuracy: 19972/35339 (56.515465%)\n",
      "Train Epoch: 41 [30000/35339 (85%)]\tLoss: 0.041443\tAccuracy: 29898/35339 (84.603413%)\n",
      "\n",
      "Validation set: Average loss: 0.001620, Accuracy: 3690/3870 (95.348837%)\n",
      "\n",
      "Train Epoch: 42 [0/35339 (0%)]\tLoss: 0.018094\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 42 [10000/35339 (28%)]\tLoss: 0.023408\tAccuracy: 10038/35339 (28.404878%)\n",
      "Train Epoch: 42 [20000/35339 (56%)]\tLoss: 0.050521\tAccuracy: 19974/35339 (56.521124%)\n",
      "Train Epoch: 42 [30000/35339 (85%)]\tLoss: 0.099744\tAccuracy: 29907/35339 (84.628880%)\n",
      "\n",
      "Validation set: Average loss: 0.001764, Accuracy: 3703/3870 (95.684755%)\n",
      "\n",
      "Train Epoch: 43 [0/35339 (0%)]\tLoss: 0.013822\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 43 [10000/35339 (28%)]\tLoss: 0.013351\tAccuracy: 10036/35339 (28.399219%)\n",
      "Train Epoch: 43 [20000/35339 (56%)]\tLoss: 0.005319\tAccuracy: 19972/35339 (56.515465%)\n",
      "Train Epoch: 43 [30000/35339 (85%)]\tLoss: 0.006951\tAccuracy: 29910/35339 (84.637369%)\n",
      "\n",
      "Validation set: Average loss: 0.001557, Accuracy: 3706/3870 (95.762274%)\n",
      "\n",
      "Train Epoch: 44 [0/35339 (0%)]\tLoss: 0.005669\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 44 [10000/35339 (28%)]\tLoss: 0.014967\tAccuracy: 10032/35339 (28.387900%)\n",
      "Train Epoch: 44 [20000/35339 (56%)]\tLoss: 0.061579\tAccuracy: 19966/35339 (56.498486%)\n",
      "Train Epoch: 44 [30000/35339 (85%)]\tLoss: 0.002205\tAccuracy: 29914/35339 (84.648688%)\n",
      "\n",
      "Validation set: Average loss: 0.001605, Accuracy: 3709/3870 (95.839793%)\n",
      "\n",
      "Train Epoch: 45 [0/35339 (0%)]\tLoss: 0.037321\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 45 [10000/35339 (28%)]\tLoss: 0.002568\tAccuracy: 10051/35339 (28.441665%)\n",
      "Train Epoch: 45 [20000/35339 (56%)]\tLoss: 0.015571\tAccuracy: 19991/35339 (56.569229%)\n",
      "Train Epoch: 45 [30000/35339 (85%)]\tLoss: 0.024137\tAccuracy: 29930/35339 (84.693964%)\n",
      "\n",
      "Validation set: Average loss: 0.001740, Accuracy: 3686/3870 (95.245478%)\n",
      "\n",
      "Train Epoch: 46 [0/35339 (0%)]\tLoss: 0.002680\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 46 [10000/35339 (28%)]\tLoss: 0.012230\tAccuracy: 10057/35339 (28.458643%)\n",
      "Train Epoch: 46 [20000/35339 (56%)]\tLoss: 0.069131\tAccuracy: 19991/35339 (56.569229%)\n",
      "Train Epoch: 46 [30000/35339 (85%)]\tLoss: 0.003387\tAccuracy: 29938/35339 (84.716602%)\n",
      "\n",
      "Validation set: Average loss: 0.001500, Accuracy: 3715/3870 (95.994832%)\n",
      "\n",
      "Train Epoch: 47 [0/35339 (0%)]\tLoss: 0.005025\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 47 [10000/35339 (28%)]\tLoss: 0.003909\tAccuracy: 10037/35339 (28.402049%)\n",
      "Train Epoch: 47 [20000/35339 (56%)]\tLoss: 0.010699\tAccuracy: 19983/35339 (56.546592%)\n",
      "Train Epoch: 47 [30000/35339 (85%)]\tLoss: 0.017222\tAccuracy: 29928/35339 (84.688305%)\n",
      "\n",
      "Validation set: Average loss: 0.001552, Accuracy: 3708/3870 (95.813953%)\n",
      "\n",
      "Train Epoch: 48 [0/35339 (0%)]\tLoss: 0.002630\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 48 [10000/35339 (28%)]\tLoss: 0.032098\tAccuracy: 10061/35339 (28.469962%)\n",
      "Train Epoch: 48 [20000/35339 (56%)]\tLoss: 0.065057\tAccuracy: 20009/35339 (56.620165%)\n",
      "Train Epoch: 48 [30000/35339 (85%)]\tLoss: 0.012316\tAccuracy: 29972/35339 (84.812813%)\n",
      "\n",
      "Validation set: Average loss: 0.001767, Accuracy: 3684/3870 (95.193798%)\n",
      "\n",
      "Train Epoch: 49 [0/35339 (0%)]\tLoss: 0.010650\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 49 [10000/35339 (28%)]\tLoss: 0.014697\tAccuracy: 10027/35339 (28.373751%)\n",
      "Train Epoch: 49 [20000/35339 (56%)]\tLoss: 0.008788\tAccuracy: 19982/35339 (56.543762%)\n",
      "Train Epoch: 49 [30000/35339 (85%)]\tLoss: 0.010980\tAccuracy: 29936/35339 (84.710943%)\n",
      "\n",
      "Validation set: Average loss: 0.001492, Accuracy: 3700/3870 (95.607235%)\n",
      "\n",
      "Train Epoch: 50 [0/35339 (0%)]\tLoss: 0.004099\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 50 [10000/35339 (28%)]\tLoss: 0.002851\tAccuracy: 10056/35339 (28.455814%)\n",
      "Train Epoch: 50 [20000/35339 (56%)]\tLoss: 0.028831\tAccuracy: 20000/35339 (56.594697%)\n",
      "Train Epoch: 50 [30000/35339 (85%)]\tLoss: 0.007898\tAccuracy: 29940/35339 (84.722262%)\n",
      "\n",
      "Validation set: Average loss: 0.001707, Accuracy: 3700/3870 (95.607235%)\n",
      "\n",
      "Train Epoch: 51 [0/35339 (0%)]\tLoss: 0.006291\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 51 [10000/35339 (28%)]\tLoss: 0.040228\tAccuracy: 10044/35339 (28.421857%)\n",
      "Train Epoch: 51 [20000/35339 (56%)]\tLoss: 0.043238\tAccuracy: 19995/35339 (56.580548%)\n",
      "Train Epoch: 51 [30000/35339 (85%)]\tLoss: 0.012146\tAccuracy: 29945/35339 (84.736410%)\n",
      "\n",
      "Validation set: Average loss: 0.001398, Accuracy: 3716/3870 (96.020672%)\n",
      "\n",
      "Train Epoch: 52 [0/35339 (0%)]\tLoss: 0.003691\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 52 [10000/35339 (28%)]\tLoss: 0.020676\tAccuracy: 10055/35339 (28.452984%)\n",
      "Train Epoch: 52 [20000/35339 (56%)]\tLoss: 0.004384\tAccuracy: 20010/35339 (56.622994%)\n",
      "Train Epoch: 52 [30000/35339 (85%)]\tLoss: 0.009916\tAccuracy: 29961/35339 (84.781686%)\n",
      "\n",
      "Validation set: Average loss: 0.001666, Accuracy: 3690/3870 (95.348837%)\n",
      "\n",
      "Train Epoch: 53 [0/35339 (0%)]\tLoss: 0.002829\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 53 [10000/35339 (28%)]\tLoss: 0.032956\tAccuracy: 10054/35339 (28.450154%)\n",
      "Train Epoch: 53 [20000/35339 (56%)]\tLoss: 0.041169\tAccuracy: 20013/35339 (56.631484%)\n",
      "Train Epoch: 53 [30000/35339 (85%)]\tLoss: 0.052036\tAccuracy: 29964/35339 (84.790175%)\n",
      "\n",
      "Validation set: Average loss: 0.001618, Accuracy: 3713/3870 (95.943152%)\n",
      "\n",
      "Train Epoch: 54 [0/35339 (0%)]\tLoss: 0.087459\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 54 [10000/35339 (28%)]\tLoss: 0.022216\tAccuracy: 10046/35339 (28.427516%)\n",
      "Train Epoch: 54 [20000/35339 (56%)]\tLoss: 0.005983\tAccuracy: 19991/35339 (56.569229%)\n",
      "Train Epoch: 54 [30000/35339 (85%)]\tLoss: 0.005692\tAccuracy: 29944/35339 (84.733580%)\n",
      "\n",
      "Validation set: Average loss: 0.001479, Accuracy: 3719/3870 (96.098191%)\n",
      "\n",
      "Train Epoch: 55 [0/35339 (0%)]\tLoss: 0.037463\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 55 [10000/35339 (28%)]\tLoss: 0.002080\tAccuracy: 10043/35339 (28.419027%)\n",
      "Train Epoch: 55 [20000/35339 (56%)]\tLoss: 0.014555\tAccuracy: 20006/35339 (56.611675%)\n",
      "Train Epoch: 55 [30000/35339 (85%)]\tLoss: 0.022956\tAccuracy: 29966/35339 (84.795835%)\n",
      "\n",
      "Validation set: Average loss: 0.001607, Accuracy: 3701/3870 (95.633075%)\n",
      "\n",
      "Train Epoch: 56 [0/35339 (0%)]\tLoss: 0.008422\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 56 [10000/35339 (28%)]\tLoss: 0.004754\tAccuracy: 10066/35339 (28.484111%)\n",
      "Train Epoch: 56 [20000/35339 (56%)]\tLoss: 0.001890\tAccuracy: 20025/35339 (56.665440%)\n",
      "Train Epoch: 56 [30000/35339 (85%)]\tLoss: 0.016287\tAccuracy: 29983/35339 (84.843940%)\n",
      "\n",
      "Validation set: Average loss: 0.001645, Accuracy: 3702/3870 (95.658915%)\n",
      "\n",
      "Train Epoch: 57 [0/35339 (0%)]\tLoss: 0.007981\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 57 [10000/35339 (28%)]\tLoss: 0.077093\tAccuracy: 10057/35339 (28.458643%)\n",
      "Train Epoch: 57 [20000/35339 (56%)]\tLoss: 0.003493\tAccuracy: 20009/35339 (56.620165%)\n",
      "Train Epoch: 57 [30000/35339 (85%)]\tLoss: 0.006095\tAccuracy: 29971/35339 (84.809983%)\n",
      "\n",
      "Validation set: Average loss: 0.001468, Accuracy: 3720/3870 (96.124031%)\n",
      "\n",
      "Train Epoch: 58 [0/35339 (0%)]\tLoss: 0.013015\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 58 [10000/35339 (28%)]\tLoss: 0.003117\tAccuracy: 10064/35339 (28.478452%)\n",
      "Train Epoch: 58 [20000/35339 (56%)]\tLoss: 0.008516\tAccuracy: 20020/35339 (56.651292%)\n",
      "Train Epoch: 58 [30000/35339 (85%)]\tLoss: 0.007424\tAccuracy: 29984/35339 (84.846770%)\n",
      "\n",
      "Validation set: Average loss: 0.001478, Accuracy: 3727/3870 (96.304910%)\n",
      "\n",
      "Train Epoch: 59 [0/35339 (0%)]\tLoss: 0.002960\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 59 [10000/35339 (28%)]\tLoss: 0.010378\tAccuracy: 10058/35339 (28.461473%)\n",
      "Train Epoch: 59 [20000/35339 (56%)]\tLoss: 0.007549\tAccuracy: 20012/35339 (56.628654%)\n",
      "Train Epoch: 59 [30000/35339 (85%)]\tLoss: 0.003054\tAccuracy: 29964/35339 (84.790175%)\n",
      "\n",
      "Validation set: Average loss: 0.001717, Accuracy: 3699/3870 (95.581395%)\n",
      "\n",
      "Train Epoch: 60 [0/35339 (0%)]\tLoss: 0.025014\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 60 [10000/35339 (28%)]\tLoss: 0.015024\tAccuracy: 10060/35339 (28.467133%)\n",
      "Train Epoch: 60 [20000/35339 (56%)]\tLoss: 0.006650\tAccuracy: 20026/35339 (56.668270%)\n",
      "Train Epoch: 60 [30000/35339 (85%)]\tLoss: 0.018021\tAccuracy: 29985/35339 (84.849600%)\n",
      "\n",
      "Validation set: Average loss: 0.001918, Accuracy: 3688/3870 (95.297158%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 61 [0/35339 (0%)]\tLoss: 0.019636\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 61 [10000/35339 (28%)]\tLoss: 0.008406\tAccuracy: 10056/35339 (28.455814%)\n",
      "Train Epoch: 61 [20000/35339 (56%)]\tLoss: 0.002452\tAccuracy: 20012/35339 (56.628654%)\n",
      "Train Epoch: 61 [30000/35339 (85%)]\tLoss: 0.062290\tAccuracy: 29976/35339 (84.824132%)\n",
      "\n",
      "Validation set: Average loss: 0.001738, Accuracy: 3718/3870 (96.072351%)\n",
      "\n",
      "Train Epoch: 62 [0/35339 (0%)]\tLoss: 0.014273\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 62 [10000/35339 (28%)]\tLoss: 0.009448\tAccuracy: 10056/35339 (28.455814%)\n",
      "Train Epoch: 62 [20000/35339 (56%)]\tLoss: 0.009245\tAccuracy: 20024/35339 (56.662611%)\n",
      "Train Epoch: 62 [30000/35339 (85%)]\tLoss: 0.005760\tAccuracy: 29993/35339 (84.872237%)\n",
      "\n",
      "Validation set: Average loss: 0.001951, Accuracy: 3705/3870 (95.736434%)\n",
      "\n",
      "Train Epoch: 63 [0/35339 (0%)]\tLoss: 0.007447\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 63 [10000/35339 (28%)]\tLoss: 0.005277\tAccuracy: 10058/35339 (28.461473%)\n",
      "Train Epoch: 63 [20000/35339 (56%)]\tLoss: 0.003406\tAccuracy: 20033/35339 (56.688078%)\n",
      "Train Epoch: 63 [30000/35339 (85%)]\tLoss: 0.021738\tAccuracy: 30005/35339 (84.906194%)\n",
      "\n",
      "Validation set: Average loss: 0.001706, Accuracy: 3712/3870 (95.917313%)\n",
      "\n",
      "Train Epoch: 64 [0/35339 (0%)]\tLoss: 0.013429\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 64 [10000/35339 (28%)]\tLoss: 0.038186\tAccuracy: 10064/35339 (28.478452%)\n",
      "Train Epoch: 64 [20000/35339 (56%)]\tLoss: 0.017350\tAccuracy: 20025/35339 (56.665440%)\n",
      "Train Epoch: 64 [30000/35339 (85%)]\tLoss: 0.003162\tAccuracy: 29992/35339 (84.869408%)\n",
      "\n",
      "Validation set: Average loss: 0.001691, Accuracy: 3715/3870 (95.994832%)\n",
      "\n",
      "Train Epoch: 65 [0/35339 (0%)]\tLoss: 0.016851\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 65 [10000/35339 (28%)]\tLoss: 0.002078\tAccuracy: 10066/35339 (28.484111%)\n",
      "Train Epoch: 65 [20000/35339 (56%)]\tLoss: 0.002780\tAccuracy: 20037/35339 (56.699397%)\n",
      "Train Epoch: 65 [30000/35339 (85%)]\tLoss: 0.003182\tAccuracy: 30004/35339 (84.903365%)\n",
      "\n",
      "Validation set: Average loss: 0.001759, Accuracy: 3700/3870 (95.607235%)\n",
      "\n",
      "Train Epoch: 66 [0/35339 (0%)]\tLoss: 0.006460\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 66 [10000/35339 (28%)]\tLoss: 0.018821\tAccuracy: 10065/35339 (28.481281%)\n",
      "Train Epoch: 66 [20000/35339 (56%)]\tLoss: 0.010406\tAccuracy: 20038/35339 (56.702227%)\n",
      "Train Epoch: 66 [30000/35339 (85%)]\tLoss: 0.000469\tAccuracy: 30009/35339 (84.917513%)\n",
      "\n",
      "Validation set: Average loss: 0.001782, Accuracy: 3706/3870 (95.762274%)\n",
      "\n",
      "Train Epoch: 67 [0/35339 (0%)]\tLoss: 0.016833\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 67 [10000/35339 (28%)]\tLoss: 0.001409\tAccuracy: 10071/35339 (28.498260%)\n",
      "Train Epoch: 67 [20000/35339 (56%)]\tLoss: 0.006502\tAccuracy: 20041/35339 (56.710716%)\n",
      "Train Epoch: 67 [30000/35339 (85%)]\tLoss: 0.007717\tAccuracy: 30004/35339 (84.903365%)\n",
      "\n",
      "Validation set: Average loss: 0.001675, Accuracy: 3711/3870 (95.891473%)\n",
      "\n",
      "Train Epoch: 68 [0/35339 (0%)]\tLoss: 0.002710\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 68 [10000/35339 (28%)]\tLoss: 0.028795\tAccuracy: 10068/35339 (28.489771%)\n",
      "Train Epoch: 68 [20000/35339 (56%)]\tLoss: 0.019075\tAccuracy: 20045/35339 (56.722035%)\n",
      "Train Epoch: 68 [30000/35339 (85%)]\tLoss: 0.004032\tAccuracy: 30011/35339 (84.923173%)\n",
      "\n",
      "Validation set: Average loss: 0.001630, Accuracy: 3726/3870 (96.279070%)\n",
      "\n",
      "Train Epoch: 69 [0/35339 (0%)]\tLoss: 0.038060\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 69 [10000/35339 (28%)]\tLoss: 0.014021\tAccuracy: 10061/35339 (28.469962%)\n",
      "Train Epoch: 69 [20000/35339 (56%)]\tLoss: 0.015908\tAccuracy: 20030/35339 (56.679589%)\n",
      "Train Epoch: 69 [30000/35339 (85%)]\tLoss: 0.036416\tAccuracy: 30005/35339 (84.906194%)\n",
      "\n",
      "Validation set: Average loss: 0.001731, Accuracy: 3722/3870 (96.175711%)\n",
      "\n",
      "Train Epoch: 70 [0/35339 (0%)]\tLoss: 0.010453\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 70 [10000/35339 (28%)]\tLoss: 0.009450\tAccuracy: 10068/35339 (28.489771%)\n",
      "Train Epoch: 70 [20000/35339 (56%)]\tLoss: 0.001177\tAccuracy: 20038/35339 (56.702227%)\n",
      "Train Epoch: 70 [30000/35339 (85%)]\tLoss: 0.001405\tAccuracy: 30011/35339 (84.923173%)\n",
      "\n",
      "Validation set: Average loss: 0.001556, Accuracy: 3725/3870 (96.253230%)\n",
      "\n",
      "Train Epoch: 71 [0/35339 (0%)]\tLoss: 0.013390\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 71 [10000/35339 (28%)]\tLoss: 0.000845\tAccuracy: 10077/35339 (28.515238%)\n",
      "Train Epoch: 71 [20000/35339 (56%)]\tLoss: 0.002400\tAccuracy: 20044/35339 (56.719205%)\n",
      "Train Epoch: 71 [30000/35339 (85%)]\tLoss: 0.007104\tAccuracy: 30005/35339 (84.906194%)\n",
      "\n",
      "Validation set: Average loss: 0.001567, Accuracy: 3727/3870 (96.304910%)\n",
      "\n",
      "Train Epoch: 72 [0/35339 (0%)]\tLoss: 0.001153\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 72 [10000/35339 (28%)]\tLoss: 0.001143\tAccuracy: 10068/35339 (28.489771%)\n",
      "Train Epoch: 72 [20000/35339 (56%)]\tLoss: 0.008466\tAccuracy: 20042/35339 (56.713546%)\n",
      "Train Epoch: 72 [30000/35339 (85%)]\tLoss: 0.012935\tAccuracy: 30003/35339 (84.900535%)\n",
      "\n",
      "Validation set: Average loss: 0.001583, Accuracy: 3714/3870 (95.968992%)\n",
      "\n",
      "Train Epoch: 73 [0/35339 (0%)]\tLoss: 0.033266\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 73 [10000/35339 (28%)]\tLoss: 0.013481\tAccuracy: 10078/35339 (28.518068%)\n",
      "Train Epoch: 73 [20000/35339 (56%)]\tLoss: 0.001947\tAccuracy: 20050/35339 (56.736184%)\n",
      "Train Epoch: 73 [30000/35339 (85%)]\tLoss: 0.001328\tAccuracy: 30019/35339 (84.945811%)\n",
      "\n",
      "Validation set: Average loss: 0.001636, Accuracy: 3719/3870 (96.098191%)\n",
      "\n",
      "Train Epoch: 74 [0/35339 (0%)]\tLoss: 0.041845\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 74 [10000/35339 (28%)]\tLoss: 0.001721\tAccuracy: 10067/35339 (28.486941%)\n",
      "Train Epoch: 74 [20000/35339 (56%)]\tLoss: 0.005117\tAccuracy: 20036/35339 (56.696568%)\n",
      "Train Epoch: 74 [30000/35339 (85%)]\tLoss: 0.005594\tAccuracy: 30008/35339 (84.914683%)\n",
      "\n",
      "Validation set: Average loss: 0.001519, Accuracy: 3726/3870 (96.279070%)\n",
      "\n",
      "Train Epoch: 75 [0/35339 (0%)]\tLoss: 0.002233\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 75 [10000/35339 (28%)]\tLoss: 0.003560\tAccuracy: 10067/35339 (28.486941%)\n",
      "Train Epoch: 75 [20000/35339 (56%)]\tLoss: 0.007090\tAccuracy: 20040/35339 (56.707886%)\n",
      "Train Epoch: 75 [30000/35339 (85%)]\tLoss: 0.022534\tAccuracy: 30014/35339 (84.931662%)\n",
      "\n",
      "Validation set: Average loss: 0.001628, Accuracy: 3712/3870 (95.917313%)\n",
      "\n",
      "Train Epoch: 76 [0/35339 (0%)]\tLoss: 0.002673\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 76 [10000/35339 (28%)]\tLoss: 0.001669\tAccuracy: 10063/35339 (28.475622%)\n",
      "Train Epoch: 76 [20000/35339 (56%)]\tLoss: 0.007294\tAccuracy: 20037/35339 (56.699397%)\n",
      "Train Epoch: 76 [30000/35339 (85%)]\tLoss: 0.003075\tAccuracy: 30002/35339 (84.897705%)\n",
      "\n",
      "Validation set: Average loss: 0.001304, Accuracy: 3750/3870 (96.899225%)\n",
      "\n",
      "Train Epoch: 77 [0/35339 (0%)]\tLoss: 0.002605\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 77 [10000/35339 (28%)]\tLoss: 0.000911\tAccuracy: 10080/35339 (28.523727%)\n",
      "Train Epoch: 77 [20000/35339 (56%)]\tLoss: 0.001059\tAccuracy: 20063/35339 (56.772970%)\n",
      "Train Epoch: 77 [30000/35339 (85%)]\tLoss: 0.000651\tAccuracy: 30029/35339 (84.974108%)\n",
      "\n",
      "Validation set: Average loss: 0.001684, Accuracy: 3721/3870 (96.149871%)\n",
      "\n",
      "Train Epoch: 78 [0/35339 (0%)]\tLoss: 0.009871\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 78 [10000/35339 (28%)]\tLoss: 0.037063\tAccuracy: 10077/35339 (28.515238%)\n",
      "Train Epoch: 78 [20000/35339 (56%)]\tLoss: 0.035832\tAccuracy: 20047/35339 (56.727695%)\n",
      "Train Epoch: 78 [30000/35339 (85%)]\tLoss: 0.003886\tAccuracy: 30025/35339 (84.962789%)\n",
      "\n",
      "Validation set: Average loss: 0.001461, Accuracy: 3731/3870 (96.408269%)\n",
      "\n",
      "Train Epoch: 79 [0/35339 (0%)]\tLoss: 0.016941\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 79 [10000/35339 (28%)]\tLoss: 0.014782\tAccuracy: 10078/35339 (28.518068%)\n",
      "Train Epoch: 79 [20000/35339 (56%)]\tLoss: 0.000767\tAccuracy: 20052/35339 (56.741843%)\n",
      "Train Epoch: 79 [30000/35339 (85%)]\tLoss: 0.046035\tAccuracy: 30020/35339 (84.948640%)\n",
      "\n",
      "Validation set: Average loss: 0.001297, Accuracy: 3740/3870 (96.640827%)\n",
      "\n",
      "Train Epoch: 80 [0/35339 (0%)]\tLoss: 0.004329\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 80 [10000/35339 (28%)]\tLoss: 0.010219\tAccuracy: 10079/35339 (28.520898%)\n",
      "Train Epoch: 80 [20000/35339 (56%)]\tLoss: 0.017491\tAccuracy: 20053/35339 (56.744673%)\n",
      "Train Epoch: 80 [30000/35339 (85%)]\tLoss: 0.000495\tAccuracy: 30029/35339 (84.974108%)\n",
      "\n",
      "Validation set: Average loss: 0.001746, Accuracy: 3710/3870 (95.865633%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch: 81 [0/35339 (0%)]\tLoss: 0.059039\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 81 [10000/35339 (28%)]\tLoss: 0.004265\tAccuracy: 10076/35339 (28.512408%)\n",
      "Train Epoch: 81 [20000/35339 (56%)]\tLoss: 0.004791\tAccuracy: 20052/35339 (56.741843%)\n",
      "Train Epoch: 81 [30000/35339 (85%)]\tLoss: 0.002541\tAccuracy: 30022/35339 (84.954300%)\n",
      "\n",
      "Validation set: Average loss: 0.001639, Accuracy: 3726/3870 (96.279070%)\n",
      "\n",
      "Train Epoch: 82 [0/35339 (0%)]\tLoss: 0.004750\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 82 [10000/35339 (28%)]\tLoss: 0.000714\tAccuracy: 10073/35339 (28.503919%)\n",
      "Train Epoch: 82 [20000/35339 (56%)]\tLoss: 0.049793\tAccuracy: 20036/35339 (56.696568%)\n",
      "Train Epoch: 82 [30000/35339 (85%)]\tLoss: 0.007302\tAccuracy: 30018/35339 (84.942981%)\n",
      "\n",
      "Validation set: Average loss: 0.001451, Accuracy: 3726/3870 (96.279070%)\n",
      "\n",
      "Train Epoch: 83 [0/35339 (0%)]\tLoss: 0.001143\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 83 [10000/35339 (28%)]\tLoss: 0.006169\tAccuracy: 10073/35339 (28.503919%)\n",
      "Train Epoch: 83 [20000/35339 (56%)]\tLoss: 0.002300\tAccuracy: 20043/35339 (56.716376%)\n",
      "Train Epoch: 83 [30000/35339 (85%)]\tLoss: 0.000961\tAccuracy: 30015/35339 (84.934492%)\n",
      "\n",
      "Validation set: Average loss: 0.001542, Accuracy: 3742/3870 (96.692506%)\n",
      "\n",
      "Train Epoch: 84 [0/35339 (0%)]\tLoss: 0.001196\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 84 [10000/35339 (28%)]\tLoss: 0.000531\tAccuracy: 10069/35339 (28.492600%)\n",
      "Train Epoch: 84 [20000/35339 (56%)]\tLoss: 0.006410\tAccuracy: 20040/35339 (56.707886%)\n",
      "Train Epoch: 84 [30000/35339 (85%)]\tLoss: 0.002318\tAccuracy: 30006/35339 (84.909024%)\n",
      "\n",
      "Validation set: Average loss: 0.001481, Accuracy: 3738/3870 (96.589147%)\n",
      "\n",
      "Train Epoch: 85 [0/35339 (0%)]\tLoss: 0.011775\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 85 [10000/35339 (28%)]\tLoss: 0.009107\tAccuracy: 10076/35339 (28.512408%)\n",
      "Train Epoch: 85 [20000/35339 (56%)]\tLoss: 0.001506\tAccuracy: 20049/35339 (56.733354%)\n",
      "Train Epoch: 85 [30000/35339 (85%)]\tLoss: 0.019479\tAccuracy: 30022/35339 (84.954300%)\n",
      "\n",
      "Validation set: Average loss: 0.001623, Accuracy: 3730/3870 (96.382429%)\n",
      "\n",
      "Train Epoch: 86 [0/35339 (0%)]\tLoss: 0.007380\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 86 [10000/35339 (28%)]\tLoss: 0.001313\tAccuracy: 10078/35339 (28.518068%)\n",
      "Train Epoch: 86 [20000/35339 (56%)]\tLoss: 0.001641\tAccuracy: 20055/35339 (56.750332%)\n",
      "Train Epoch: 86 [30000/35339 (85%)]\tLoss: 0.000355\tAccuracy: 30030/35339 (84.976938%)\n",
      "\n",
      "Validation set: Average loss: 0.001580, Accuracy: 3731/3870 (96.408269%)\n",
      "\n",
      "Train Epoch: 87 [0/35339 (0%)]\tLoss: 0.003590\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 87 [10000/35339 (28%)]\tLoss: 0.001290\tAccuracy: 10078/35339 (28.518068%)\n",
      "Train Epoch: 87 [20000/35339 (56%)]\tLoss: 0.009464\tAccuracy: 20056/35339 (56.753162%)\n",
      "Train Epoch: 87 [30000/35339 (85%)]\tLoss: 0.005228\tAccuracy: 30023/35339 (84.957130%)\n",
      "\n",
      "Validation set: Average loss: 0.001830, Accuracy: 3720/3870 (96.124031%)\n",
      "\n",
      "Train Epoch: 88 [0/35339 (0%)]\tLoss: 0.001156\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 88 [10000/35339 (28%)]\tLoss: 0.000849\tAccuracy: 10079/35339 (28.520898%)\n",
      "Train Epoch: 88 [20000/35339 (56%)]\tLoss: 0.006850\tAccuracy: 20056/35339 (56.753162%)\n",
      "Train Epoch: 88 [30000/35339 (85%)]\tLoss: 0.041330\tAccuracy: 30032/35339 (84.982597%)\n",
      "\n",
      "Validation set: Average loss: 0.001433, Accuracy: 3731/3870 (96.408269%)\n",
      "\n",
      "Train Epoch: 89 [0/35339 (0%)]\tLoss: 0.000418\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 89 [10000/35339 (28%)]\tLoss: 0.004925\tAccuracy: 10080/35339 (28.523727%)\n",
      "Train Epoch: 89 [20000/35339 (56%)]\tLoss: 0.009608\tAccuracy: 20064/35339 (56.775800%)\n",
      "Train Epoch: 89 [30000/35339 (85%)]\tLoss: 0.001378\tAccuracy: 30039/35339 (85.002405%)\n",
      "\n",
      "Validation set: Average loss: 0.001126, Accuracy: 3756/3870 (97.054264%)\n",
      "\n",
      "Train Epoch: 90 [0/35339 (0%)]\tLoss: 0.016766\tAccuracy: 98/35339 (0.277314%)\n",
      "Train Epoch: 90 [10000/35339 (28%)]\tLoss: 0.112842\tAccuracy: 10069/35339 (28.492600%)\n",
      "Train Epoch: 90 [20000/35339 (56%)]\tLoss: 0.001505\tAccuracy: 20055/35339 (56.750332%)\n",
      "Train Epoch: 90 [30000/35339 (85%)]\tLoss: 0.007414\tAccuracy: 30022/35339 (84.954300%)\n",
      "\n",
      "Validation set: Average loss: 0.001412, Accuracy: 3731/3870 (96.408269%)\n",
      "\n",
      "Train Epoch: 91 [0/35339 (0%)]\tLoss: 0.023919\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 91 [10000/35339 (28%)]\tLoss: 0.002249\tAccuracy: 10082/35339 (28.529387%)\n",
      "Train Epoch: 91 [20000/35339 (56%)]\tLoss: 0.000798\tAccuracy: 20054/35339 (56.747503%)\n",
      "Train Epoch: 91 [30000/35339 (85%)]\tLoss: 0.005480\tAccuracy: 30030/35339 (84.976938%)\n",
      "\n",
      "Validation set: Average loss: 0.001516, Accuracy: 3724/3870 (96.227390%)\n",
      "\n",
      "Train Epoch: 92 [0/35339 (0%)]\tLoss: 0.016136\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 92 [10000/35339 (28%)]\tLoss: 0.004265\tAccuracy: 10071/35339 (28.498260%)\n",
      "Train Epoch: 92 [20000/35339 (56%)]\tLoss: 0.003972\tAccuracy: 20045/35339 (56.722035%)\n",
      "Train Epoch: 92 [30000/35339 (85%)]\tLoss: 0.009603\tAccuracy: 30018/35339 (84.942981%)\n",
      "\n",
      "Validation set: Average loss: 0.001649, Accuracy: 3724/3870 (96.227390%)\n",
      "\n",
      "Train Epoch: 93 [0/35339 (0%)]\tLoss: 0.020521\tAccuracy: 99/35339 (0.280144%)\n",
      "Train Epoch: 93 [10000/35339 (28%)]\tLoss: 0.004246\tAccuracy: 10076/35339 (28.512408%)\n",
      "Train Epoch: 93 [20000/35339 (56%)]\tLoss: 0.002272\tAccuracy: 20056/35339 (56.753162%)\n",
      "Train Epoch: 93 [30000/35339 (85%)]\tLoss: 0.005446\tAccuracy: 30032/35339 (84.982597%)\n",
      "\n",
      "Validation set: Average loss: 0.001296, Accuracy: 3737/3870 (96.563307%)\n",
      "\n",
      "Train Epoch: 94 [0/35339 (0%)]\tLoss: 0.001558\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 94 [10000/35339 (28%)]\tLoss: 0.001380\tAccuracy: 10083/35339 (28.532217%)\n",
      "Train Epoch: 94 [20000/35339 (56%)]\tLoss: 0.001955\tAccuracy: 20063/35339 (56.772970%)\n",
      "Train Epoch: 94 [30000/35339 (85%)]\tLoss: 0.001663\tAccuracy: 30045/35339 (85.019384%)\n",
      "\n",
      "Validation set: Average loss: 0.001598, Accuracy: 3714/3870 (95.968992%)\n",
      "\n",
      "Train Epoch: 95 [0/35339 (0%)]\tLoss: 0.000703\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 95 [10000/35339 (28%)]\tLoss: 0.000949\tAccuracy: 10078/35339 (28.518068%)\n",
      "Train Epoch: 95 [20000/35339 (56%)]\tLoss: 0.007073\tAccuracy: 20055/35339 (56.750332%)\n",
      "Train Epoch: 95 [30000/35339 (85%)]\tLoss: 0.002143\tAccuracy: 30029/35339 (84.974108%)\n",
      "\n",
      "Validation set: Average loss: 0.001518, Accuracy: 3716/3870 (96.020672%)\n",
      "\n",
      "Train Epoch: 96 [0/35339 (0%)]\tLoss: 0.001290\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 96 [10000/35339 (28%)]\tLoss: 0.000142\tAccuracy: 10074/35339 (28.506749%)\n",
      "Train Epoch: 96 [20000/35339 (56%)]\tLoss: 0.028663\tAccuracy: 20054/35339 (56.747503%)\n",
      "Train Epoch: 96 [30000/35339 (85%)]\tLoss: 0.019221\tAccuracy: 30025/35339 (84.962789%)\n",
      "\n",
      "Validation set: Average loss: 0.001274, Accuracy: 3721/3870 (96.149871%)\n",
      "\n",
      "Train Epoch: 97 [0/35339 (0%)]\tLoss: 0.005817\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 97 [10000/35339 (28%)]\tLoss: 0.011004\tAccuracy: 10076/35339 (28.512408%)\n",
      "Train Epoch: 97 [20000/35339 (56%)]\tLoss: 0.000538\tAccuracy: 20059/35339 (56.761651%)\n",
      "Train Epoch: 97 [30000/35339 (85%)]\tLoss: 0.028218\tAccuracy: 30026/35339 (84.965619%)\n",
      "\n",
      "Validation set: Average loss: 0.001702, Accuracy: 3711/3870 (95.891473%)\n",
      "\n",
      "Train Epoch: 98 [0/35339 (0%)]\tLoss: 0.001003\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 98 [10000/35339 (28%)]\tLoss: 0.000744\tAccuracy: 10079/35339 (28.520898%)\n",
      "Train Epoch: 98 [20000/35339 (56%)]\tLoss: 0.040491\tAccuracy: 20055/35339 (56.750332%)\n",
      "Train Epoch: 98 [30000/35339 (85%)]\tLoss: 0.007309\tAccuracy: 30031/35339 (84.979767%)\n",
      "\n",
      "Validation set: Average loss: 0.001473, Accuracy: 3711/3870 (95.891473%)\n",
      "\n",
      "Train Epoch: 99 [0/35339 (0%)]\tLoss: 0.001470\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 99 [10000/35339 (28%)]\tLoss: 0.008696\tAccuracy: 10079/35339 (28.520898%)\n",
      "Train Epoch: 99 [20000/35339 (56%)]\tLoss: 0.037028\tAccuracy: 20055/35339 (56.750332%)\n",
      "Train Epoch: 99 [30000/35339 (85%)]\tLoss: 0.000639\tAccuracy: 30040/35339 (85.005235%)\n",
      "\n",
      "Validation set: Average loss: 0.001685, Accuracy: 3727/3870 (96.304910%)\n",
      "\n",
      "Train Epoch: 100 [0/35339 (0%)]\tLoss: 0.000883\tAccuracy: 100/35339 (0.282973%)\n",
      "Train Epoch: 100 [10000/35339 (28%)]\tLoss: 0.021889\tAccuracy: 10080/35339 (28.523727%)\n",
      "Train Epoch: 100 [20000/35339 (56%)]\tLoss: 0.000392\tAccuracy: 20059/35339 (56.761651%)\n",
      "Train Epoch: 100 [30000/35339 (85%)]\tLoss: 0.033445\tAccuracy: 30040/35339 (85.005235%)\n",
      "\n",
      "Validation set: Average loss: 0.001540, Accuracy: 3723/3870 (96.201550%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_loss_log = []\n",
    "training_accuracy_log = []\n",
    "validation_loss_log = []\n",
    "validation_accuracy_log = []\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    training_loss, training_accuracy = train(epoch)\n",
    "    validation_loss, validation_accuracy = validation() \n",
    "    \n",
    "    training_loss_log.append(training_loss)\n",
    "    training_accuracy_log.append(training_accuracy)\n",
    "    validation_loss_log.append(validation_loss)\n",
    "    validation_accuracy_log.append(validation_accuracy)\n",
    "    \n",
    "    if validation_accuracy > best_acc:\n",
    "        best_acc = validation_accuracy\n",
    "        torch.save(model.state_dict(), \"model_Net_5_best.pth\")\n",
    "\n",
    "    torch.save(model.state_dict(), \"model_Net_5_\" + str(epoch) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.35703706741333,\n",
       " 1.459616780281067,\n",
       " 0.7817439436912537,\n",
       " 0.6034301519393921,\n",
       " 0.5136042833328247,\n",
       " 0.3112473785877228,\n",
       " 0.3255736529827118,\n",
       " 0.16546334326267242,\n",
       " 0.2771284282207489,\n",
       " 0.27081361413002014,\n",
       " 0.09266720712184906,\n",
       " 0.04675436019897461,\n",
       " 0.1129666194319725,\n",
       " 0.06405391544103622,\n",
       " 0.03172930330038071,\n",
       " 0.34330514073371887,\n",
       " 0.13505111634731293,\n",
       " 0.06603546440601349,\n",
       " 0.11529804766178131,\n",
       " 0.3614964187145233,\n",
       " 0.055012643337249756,\n",
       " 0.036679647862911224,\n",
       " 0.014437217265367508,\n",
       " 0.059026606380939484,\n",
       " 0.017712755128741264,\n",
       " 0.026736078783869743,\n",
       " 0.051045339554548264,\n",
       " 0.007028455380350351,\n",
       " 0.0065338267013430595,\n",
       " 0.00696925725787878,\n",
       " 0.1672004610300064,\n",
       " 0.002641758183017373,\n",
       " 0.09932450205087662,\n",
       " 0.022602664306759834,\n",
       " 0.014482088387012482,\n",
       " 0.055322304368019104,\n",
       " 0.004141081124544144,\n",
       " 0.009789376519620419,\n",
       " 0.032681919634342194,\n",
       " 0.01677432842552662,\n",
       " 0.02527850680053234,\n",
       " 0.006948673631995916,\n",
       " 0.000677490490488708,\n",
       " 0.04134346544742584,\n",
       " 0.00979691930115223,\n",
       " 0.0008401923114433885,\n",
       " 0.004907896276563406,\n",
       " 0.013179137371480465,\n",
       " 0.006939565297216177,\n",
       " 0.018248017877340317,\n",
       " 0.002421571174636483,\n",
       " 0.007173954043537378,\n",
       " 0.005558422766625881,\n",
       " 0.018890807405114174,\n",
       " 0.0013661808334290981,\n",
       " 0.0011404466349631548,\n",
       " 0.0010459867771714926,\n",
       " 0.0006818402907811105,\n",
       " 0.003815537551417947,\n",
       " 0.0057907369919121265,\n",
       " 0.011602823622524738,\n",
       " 0.0029766964726150036,\n",
       " 0.024676503613591194,\n",
       " 0.0007683850708417594,\n",
       " 0.016340769827365875,\n",
       " 0.024422932416200638,\n",
       " 0.09511154145002365,\n",
       " 0.12320198118686676,\n",
       " 0.09165868163108826,\n",
       " 0.0009085397468879819,\n",
       " 0.006276407744735479,\n",
       " 0.0006458931020461023,\n",
       " 0.004077943507581949,\n",
       " 0.0003160745545756072,\n",
       " 0.0025106333196163177,\n",
       " 0.00995675940066576,\n",
       " 0.007365035824477673,\n",
       " 0.013377365656197071,\n",
       " 0.011509684845805168,\n",
       " 0.0032299018930643797,\n",
       " 0.0012288398575037718,\n",
       " 0.014975771307945251,\n",
       " 0.005569509230554104,\n",
       " 0.004191081039607525,\n",
       " 0.0012402229476720095,\n",
       " 0.10784440487623215,\n",
       " 0.00047594853094778955,\n",
       " 0.003866966813802719,\n",
       " 0.0020380259957164526,\n",
       " 0.0008797883638180792,\n",
       " 0.0003746433067135513,\n",
       " 0.015144674107432365,\n",
       " 0.0006344287539832294,\n",
       " 0.010785290971398354,\n",
       " 3.457462662481703e-05,\n",
       " 0.0001594068598933518,\n",
       " 0.00040027915383689106,\n",
       " 0.0026972058694809675,\n",
       " 0.00013147805293556303,\n",
       " 0.00046569196274504066]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.033900223549054,\n",
       " 42.658252921701234,\n",
       " 59.690427006989445,\n",
       " 73.07507286567248,\n",
       " 81.08322250205156,\n",
       " 85.96451512493279,\n",
       " 89.02345850193836,\n",
       " 91.21367327881377,\n",
       " 92.71626248620504,\n",
       " 93.81419960949658,\n",
       " 94.81875548261128,\n",
       " 95.43563768074931,\n",
       " 95.99026571210278,\n",
       " 96.2732391974872,\n",
       " 96.73731571351765,\n",
       " 97.13064885820198,\n",
       " 97.35136817680183,\n",
       " 97.64000113189394,\n",
       " 97.80695548827075,\n",
       " 97.89750700359376,\n",
       " 98.16633181470897,\n",
       " 98.27952120886273,\n",
       " 98.40685927728572,\n",
       " 98.43515662582416,\n",
       " 98.67285435354707,\n",
       " 98.64738673986247,\n",
       " 98.83414924021619,\n",
       " 98.69549223237783,\n",
       " 98.87942499787769,\n",
       " 98.9247007555392,\n",
       " 98.96997651320072,\n",
       " 98.96997651320072,\n",
       " 99.07184696793911,\n",
       " 99.12844166501598,\n",
       " 99.16522821811596,\n",
       " 99.1935255666544,\n",
       " 99.1737174226775,\n",
       " 99.20767424092362,\n",
       " 99.1737174226775,\n",
       " 99.25577973343897,\n",
       " 99.3406717790543,\n",
       " 99.32935283963893,\n",
       " 99.35765018817737,\n",
       " 99.38877727156965,\n",
       " 99.42556382466962,\n",
       " 99.4425422337927,\n",
       " 99.44820170350039,\n",
       " 99.57836950677722,\n",
       " 99.4425422337927,\n",
       " 99.47649905203882,\n",
       " 99.49347746116189,\n",
       " 99.55007215823878,\n",
       " 99.53592348396955,\n",
       " 99.51611533999264,\n",
       " 99.53592348396955,\n",
       " 99.60383712046182,\n",
       " 99.55573162794646,\n",
       " 99.6094965901695,\n",
       " 99.53309374911571,\n",
       " 99.61798579473103,\n",
       " 99.59817765075412,\n",
       " 99.64345340841564,\n",
       " 99.66326155239254,\n",
       " 99.64628314326947,\n",
       " 99.68872916607714,\n",
       " 99.67458049180792,\n",
       " 99.68306969636944,\n",
       " 99.70287784034636,\n",
       " 99.68306969636944,\n",
       " 99.70287784034636,\n",
       " 99.70004810549251,\n",
       " 99.68589943122329,\n",
       " 99.73966439344633,\n",
       " 99.66892102210024,\n",
       " 99.70570757520021,\n",
       " 99.70004810549251,\n",
       " 99.75098333286171,\n",
       " 99.74249412830018,\n",
       " 99.73683465859249,\n",
       " 99.74249412830018,\n",
       " 99.73683465859249,\n",
       " 99.71419677976174,\n",
       " 99.73683465859249,\n",
       " 99.70570757520021,\n",
       " 99.74815359800786,\n",
       " 99.77079147683862,\n",
       " 99.72551571917711,\n",
       " 99.7764509465463,\n",
       " 99.79908882537707,\n",
       " 99.72834545403096,\n",
       " 99.7764509465463,\n",
       " 99.7311751888848,\n",
       " 99.76796174198478,\n",
       " 99.8075780299386,\n",
       " 99.76796174198478,\n",
       " 99.74815359800786,\n",
       " 99.75947253742325,\n",
       " 99.76796174198478,\n",
       " 99.80474829508475,\n",
       " 99.77079147683862]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_accuracy_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03447743740500714,\n",
       " 0.0240521098138134,\n",
       " 0.015834252461213474,\n",
       " 0.010721746736834216,\n",
       " 0.008101607868279443,\n",
       " 0.006069035510934446,\n",
       " 0.004970446970188649,\n",
       " 0.004675362360945274,\n",
       " 0.0038261663299823992,\n",
       " 0.0036091577509557706,\n",
       " 0.0033739444701053993,\n",
       " 0.0030832558546638844,\n",
       " 0.0030240302144378924,\n",
       " 0.0029055752012354034,\n",
       " 0.0026726137528446255,\n",
       " 0.002805984736773972,\n",
       " 0.0026248316095241896,\n",
       " 0.0023749370235758437,\n",
       " 0.002258747883829305,\n",
       " 0.0024036161050751555,\n",
       " 0.002211025343348756,\n",
       " 0.002254135277752767,\n",
       " 0.0022146897391387256,\n",
       " 0.002126114109280767,\n",
       " 0.0020331547448161308,\n",
       " 0.00199799515086302,\n",
       " 0.0020077841097771165,\n",
       " 0.002068029716516904,\n",
       " 0.002013609104948323,\n",
       " 0.0018572817961983166,\n",
       " 0.001881329234854471,\n",
       " 0.001793845287567481,\n",
       " 0.0018683201098281864,\n",
       " 0.0021154988014280016,\n",
       " 0.0018233071774755995,\n",
       " 0.001882786549937921,\n",
       " 0.0018708895632414478,\n",
       " 0.0017434350227250794,\n",
       " 0.0016753545174458954,\n",
       " 0.0016730391220438556,\n",
       " 0.0016204925027812195,\n",
       " 0.001763613121690847,\n",
       " 0.0015572371516245954,\n",
       " 0.0016049008756862907,\n",
       " 0.0017402729500328098,\n",
       " 0.0015002060534407863,\n",
       " 0.0015519055217831338,\n",
       " 0.001767170270242542,\n",
       " 0.0014921296684758632,\n",
       " 0.0017066270898522143,\n",
       " 0.001398180792843595,\n",
       " 0.0016655050320260136,\n",
       " 0.0016181094633812491,\n",
       " 0.0014785035081343195,\n",
       " 0.0016066425642651718,\n",
       " 0.0016452432033843875,\n",
       " 0.0014682543737746447,\n",
       " 0.0014780762491045372,\n",
       " 0.0017167187415207058,\n",
       " 0.0019177778579726689,\n",
       " 0.0017378917325699928,\n",
       " 0.0019510316622491403,\n",
       " 0.0017064664191043179,\n",
       " 0.0016909824386831657,\n",
       " 0.0017591470951760768,\n",
       " 0.0017823991070511603,\n",
       " 0.0016746590472375218,\n",
       " 0.001629915258204411,\n",
       " 0.0017314734515217348,\n",
       " 0.001555517207238229,\n",
       " 0.0015673895498786114,\n",
       " 0.0015826636283849233,\n",
       " 0.001636191683957372,\n",
       " 0.001518945005058488,\n",
       " 0.0016276213792807961,\n",
       " 0.001303745901625538,\n",
       " 0.001684260349675324,\n",
       " 0.001461421667574461,\n",
       " 0.0012969157352507646,\n",
       " 0.0017456585174650807,\n",
       " 0.0016386155936736256,\n",
       " 0.0014512390260290812,\n",
       " 0.0015415424217526108,\n",
       " 0.001480796588124769,\n",
       " 0.0016230741214060455,\n",
       " 0.0015796618776993013,\n",
       " 0.001829760953587914,\n",
       " 0.0014332331181539319,\n",
       " 0.0011258753027365176,\n",
       " 0.0014123918840139944,\n",
       " 0.0015163863416303282,\n",
       " 0.001648836644736361,\n",
       " 0.001295854288295154,\n",
       " 0.0015982587975811732,\n",
       " 0.0015180855670162434,\n",
       " 0.0012742133993179667,\n",
       " 0.0017020878358418182,\n",
       " 0.0014733783783015188,\n",
       " 0.001684928148253613,\n",
       " 0.0015399233270046617]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_loss_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16.718346253229974,\n",
       " 31.498708010335918,\n",
       " 56.950904392764855,\n",
       " 70.36175710594316,\n",
       " 76.97674418604652,\n",
       " 83.82428940568475,\n",
       " 86.89922480620154,\n",
       " 87.77777777777777,\n",
       " 90.31007751937985,\n",
       " 90.98191214470285,\n",
       " 91.7312661498708,\n",
       " 92.63565891472868,\n",
       " 92.48062015503876,\n",
       " 92.86821705426357,\n",
       " 93.4625322997416,\n",
       " 93.22997416020672,\n",
       " 93.25581395348837,\n",
       " 94.05684754521964,\n",
       " 94.57364341085271,\n",
       " 93.90180878552971,\n",
       " 94.49612403100775,\n",
       " 94.31524547803618,\n",
       " 94.31524547803618,\n",
       " 94.49612403100775,\n",
       " 94.5219638242894,\n",
       " 94.65116279069767,\n",
       " 94.62532299741602,\n",
       " 94.8062015503876,\n",
       " 94.88372093023256,\n",
       " 94.83204134366925,\n",
       " 94.83204134366925,\n",
       " 95.4780361757106,\n",
       " 95.1937984496124,\n",
       " 94.59948320413437,\n",
       " 94.93540051679587,\n",
       " 95.5297157622739,\n",
       " 95.21963824289406,\n",
       " 95.27131782945736,\n",
       " 95.68475452196382,\n",
       " 95.68475452196382,\n",
       " 95.34883720930233,\n",
       " 95.68475452196382,\n",
       " 95.76227390180878,\n",
       " 95.83979328165374,\n",
       " 95.24547803617571,\n",
       " 95.99483204134367,\n",
       " 95.81395348837209,\n",
       " 95.1937984496124,\n",
       " 95.60723514211887,\n",
       " 95.60723514211887,\n",
       " 96.02067183462532,\n",
       " 95.34883720930233,\n",
       " 95.94315245478036,\n",
       " 96.09819121447029,\n",
       " 95.63307493540051,\n",
       " 95.65891472868218,\n",
       " 96.12403100775194,\n",
       " 96.30490956072352,\n",
       " 95.5813953488372,\n",
       " 95.29715762273902,\n",
       " 96.07235142118863,\n",
       " 95.73643410852713,\n",
       " 95.91731266149871,\n",
       " 95.99483204134367,\n",
       " 95.60723514211887,\n",
       " 95.76227390180878,\n",
       " 95.89147286821705,\n",
       " 96.27906976744185,\n",
       " 96.17571059431525,\n",
       " 96.2532299741602,\n",
       " 96.30490956072352,\n",
       " 95.96899224806202,\n",
       " 96.09819121447029,\n",
       " 96.27906976744185,\n",
       " 95.91731266149871,\n",
       " 96.89922480620154,\n",
       " 96.14987080103359,\n",
       " 96.40826873385014,\n",
       " 96.64082687338501,\n",
       " 95.8656330749354,\n",
       " 96.27906976744185,\n",
       " 96.27906976744185,\n",
       " 96.69250645994832,\n",
       " 96.5891472868217,\n",
       " 96.38242894056847,\n",
       " 96.40826873385014,\n",
       " 96.12403100775194,\n",
       " 96.40826873385014,\n",
       " 97.05426356589147,\n",
       " 96.40826873385014,\n",
       " 96.22739018087856,\n",
       " 96.22739018087856,\n",
       " 96.56330749354005,\n",
       " 95.96899224806202,\n",
       " 96.02067183462532,\n",
       " 96.14987080103359,\n",
       " 95.89147286821705,\n",
       " 95.89147286821705,\n",
       " 96.30490956072352,\n",
       " 96.2015503875969]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_accuracy_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "time = list(range(100))\n",
    "\n",
    "plt.plot(time,training_loss_log)\n",
    "plt.plot(time,validation_loss_log)\n",
    "plt.legend(['Training loss', 'Validation loss'], loc='upper right')\n",
    "plt.ylabel(u'Cross Entrophy Loss',fontproperties='SimHei')\n",
    "plt.xlabel(u'Time',fontproperties='SimHei')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "time = list(range(100))\n",
    "\n",
    "plt.plot(time,training_accuracy_log)\n",
    "plt.plot(time,validation_accuracy_log)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='lower right')\n",
    "plt.ylabel(u'Accuracy',fontproperties='SimHei')\n",
    "plt.xlabel(u'Time',fontproperties='SimHei')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(validation_accuracy_log)):\n",
    "    if validation_accuracy_log[i]>97:\n",
    "        print(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
